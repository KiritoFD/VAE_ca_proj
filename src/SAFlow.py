import torch
import torch.nn as nn
import math

class SinusoidalTimeEmbedding(nn.Module):
    """æ­£å¼¦ä½ç½®ç¼–ç  - æ ‡å‡† Transformer æ—¶é—´ç¼–ç """
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
    
    def forward(self, t):
        device = t.device
        half_dim = self.dim // 2
        embeddings = math.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = t[:, None] * embeddings[None, :]
        embeddings = torch.cat([embeddings.sin(), embeddings.cos()], dim=-1)
        return embeddings


class AdaGN(nn.Module):
    """
    è‡ªé€‚åº”ç»„å½’ä¸€åŒ– (Adaptive Group Normalization)
    æ ¸å¿ƒï¼šè®©é£æ ¼/æ—¶é—´æ¡ä»¶ç›´æ¥æ§åˆ¶æ¯å±‚ç‰¹å¾çš„åˆ†å¸ƒï¼ˆå‡å€¼+æ–¹å·®ï¼‰
    è¿™æ˜¯ç¡®ä¿æ¡ä»¶ä¿¡å·ä¸è¢«å¿½ç•¥çš„å…³é”®ç»„ä»¶
    """
    def __init__(self, channels, cond_dim):
        super().__init__()
        self.norm = nn.GroupNorm(32, channels, eps=1e-6, affine=False)
        
        # ğŸŸ¢ å…³é”®ï¼šä»æ¡ä»¶é¢„æµ‹ scale & shift
        self.modulation = nn.Sequential(
            nn.SiLU(),
            nn.Linear(cond_dim, channels * 2)
        )
        
    def forward(self, x, cond):
        """
        Args:
            x: [B, C, H, W]
            cond: [B, cond_dim] - é£æ ¼+æ—¶é—´çš„èåˆåµŒå…¥
        """
        # 1. æ ‡å‡†å½’ä¸€åŒ–ï¼ˆé›¶å‡å€¼å•ä½æ–¹å·®ï¼‰
        x = self.norm(x)
        
        # 2. ä»æ¡ä»¶é¢„æµ‹è°ƒåˆ¶å‚æ•°
        scale_shift = self.modulation(cond)
        scale, shift = scale_shift.chunk(2, dim=1)
        
        # 3. åº”ç”¨è°ƒåˆ¶ï¼ˆå¹¿æ’­åˆ°ç©ºé—´ç»´åº¦ï¼‰
        # ğŸŸ¢ å…¬å¼: x = x * (1 + scale) + shift
        x = x * (1 + scale[:, :, None, None]) + shift[:, :, None, None]
        
        return x


class ContentFusion(nn.Module):
    """
    å†…å®¹èåˆæ¨¡å— - ç¡®ä¿ç”Ÿæˆå›¾ä¿ç•™åŸå›¾ç»“æ„
    ä½¿ç”¨é—¨æ§æœºåˆ¶åŠ¨æ€å¹³è¡¡å†…å®¹æ³¨å…¥å¼ºåº¦
    """
    def __init__(self, dim):
        super().__init__()
        self.content_proj = nn.Sequential(
            nn.GroupNorm(32, dim),
            nn.SiLU(),
            nn.Conv2d(dim, dim, 3, padding=1)
        )
        
        # ğŸŸ¢ æ—¶é—´æ„ŸçŸ¥é—¨æ§ï¼šæ—©æœŸå¤šæ³¨å…¥å†…å®¹ï¼ŒåæœŸå¤šæ³¨å…¥é£æ ¼
        self.time_gate = nn.Sequential(
            nn.Linear(dim, dim),
            nn.Sigmoid()
        )
        
    def forward(self, x, x_content, time_emb):
        """
        Args:
            x: å½“å‰ç‰¹å¾ [B, C, H, W]
            x_content: åŸå›¾ç‰¹å¾ [B, C, H, W]
            time_emb: æ—¶é—´åµŒå…¥ [B, dim]
        """
        # è®¡ç®—æ—¶é—´é—¨æ§ç³»æ•°
        alpha = self.time_gate(time_emb)[:, :, None, None]
        
        # æå–å†…å®¹ç‰¹å¾å¹¶èåˆ
        content_feat = self.content_proj(x_content)
        return x + content_feat * alpha


class SAFBlock(nn.Module):
    """
    SA-Flow Block v2 (AdaGN-Based)
    æ ¸å¿ƒæ”¹è¿›ï¼šæ‰€æœ‰å½’ä¸€åŒ–å±‚éƒ½æ¢æˆ AdaGNï¼Œå¼ºåˆ¶æ³¨å…¥æ¡ä»¶ä¿¡å·
    """
    def __init__(self, dim, kernel_size=7):
        super().__init__()
        
        # ğŸŸ¢ è·¯å¾„1: è‡ªé€‚åº”å½’ä¸€åŒ– + ç©ºé—´å·ç§¯
        self.ada_gn1 = AdaGN(dim, dim)
        self.dwconv = nn.Conv2d(
            dim, dim, 
            kernel_size=kernel_size, 
            padding=kernel_size//2, 
            groups=dim  # Depthwise Conv
        )
        
        # ğŸŸ¢ è·¯å¾„2: Inverted Bottleneck (ConvNeXt style)
        self.ada_gn2 = AdaGN(dim, dim)
        self.pwconv1 = nn.Conv2d(dim, dim * 4, 1)
        self.act = nn.SiLU()
        self.pwconv2 = nn.Conv2d(dim * 4, dim, 1)
        
        # ğŸŸ¢ å†…å®¹èåˆ
        self.content_fusion = ContentFusion(dim)
        
        # Layer Scale (ç¨³å®šæ·±å±‚è®­ç»ƒ)
        self.gamma = nn.Parameter(torch.ones(dim, 1, 1) * 1e-6)
        
    def forward(self, x, x_content, global_cond, time_emb):
        """
        Args:
            x: [B, C, H, W]
            x_content: [B, C, H, W] åŸå›¾ç‰¹å¾
            global_cond: [B, dim] é£æ ¼+æ—¶é—´åµŒå…¥
            time_emb: [B, dim] æ—¶é—´åµŒå…¥ï¼ˆç”¨äºé—¨æ§ï¼‰
        """
        shortcut = x
        
        # ğŸŸ¢ Stage 1: æ¡ä»¶å½’ä¸€åŒ– + ç©ºé—´å»ºæ¨¡
        x = self.ada_gn1(x, global_cond)
        x = self.dwconv(x)
        
        # ğŸŸ¢ Stage 2: æ¡ä»¶å½’ä¸€åŒ– + é€šé“æ··åˆ
        x = self.ada_gn2(x, global_cond)
        x = self.pwconv1(x)
        x = self.act(x)
        x = self.pwconv2(x)
        
        # ğŸŸ¢ Stage 3: å†…å®¹æ³¨å…¥
        x = self.content_fusion(x, x_content, time_emb)
        
        # ğŸŸ¢ æ®‹å·®è¿æ¥ + Layer Scale
        return shortcut + x * self.gamma


class SAFModel(nn.Module):
    """
    SA-Flow v2: AdaGN-Based Conditional Flow Matching
    
    æ ¸å¿ƒæ”¹è¿›:
    1. å…¨å±€ä½¿ç”¨ AdaGN æ›¿ä»£æ™®é€šå½’ä¸€åŒ–
    2. æ”¯æŒ Classifier-Free Guidance (CFG)
    3. ç‹¬ç«‹çš„å†…å®¹ç¼–ç å™¨
    4. æ—¶é—´æ„ŸçŸ¥çš„å†…å®¹èåˆ
    """
    def __init__(
        self, 
        latent_channels=4, 
        hidden_dim=256, 
        num_layers=8, 
        num_styles=2, 
        kernel_size=7,
        **kwargs
    ):
        super().__init__()
        
        # ğŸŸ¢ æ ¸å¿ƒï¼šNull Class æ”¯æŒ (CFG å¿…éœ€)
        self.num_styles = num_styles
        self.null_class_id = num_styles  # æœ€åä¸€ä¸ª ID æ˜¯ç©ºç±»åˆ«
        
        # ğŸŸ¢ æ—¶é—´åµŒå…¥ (æ­£å¼¦ç¼–ç )
        self.time_embed = nn.Sequential(
            SinusoidalTimeEmbedding(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # ğŸŸ¢ é£æ ¼åµŒå…¥ (æ”¯æŒ N+1 ä¸ªç±»åˆ«)
        self.style_embed = nn.Embedding(num_styles + 1, hidden_dim)
        
        # ğŸŸ¢ è¾“å…¥æŠ•å½±
        self.stem = nn.Conv2d(latent_channels, hidden_dim, 3, padding=1)
        
        # ğŸŸ¢ ç‹¬ç«‹çš„å†…å®¹ç¼–ç å™¨
        self.content_encoder = nn.Sequential(
            nn.Conv2d(latent_channels, hidden_dim // 2, 3, padding=1),
            nn.GroupNorm(16, hidden_dim // 2),
            nn.SiLU(),
            nn.Conv2d(hidden_dim // 2, hidden_dim, 3, padding=1),
            nn.GroupNorm(32, hidden_dim),
            nn.SiLU(),
            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1)
        )
        
        # ğŸŸ¢ ä¸»å¹²ç½‘ç»œ (å…¨éƒ¨ä½¿ç”¨ AdaGN)
        self.blocks = nn.ModuleList([
            SAFBlock(hidden_dim, kernel_size) 
            for _ in range(num_layers)
        ])
        
        # ğŸŸ¢ è¾“å‡ºå±‚
        self.final_norm = nn.GroupNorm(32, hidden_dim)
        self.final = nn.Conv2d(hidden_dim, latent_channels, 3, padding=1)
        
        # ğŸŸ¢ é›¶åˆå§‹åŒ–æœ€åä¸€å±‚ï¼ˆæ ‡å‡† Diffusion å®è·µï¼‰
        nn.init.zeros_(self.final.weight)
        nn.init.zeros_(self.final.bias)
        
    def forward(self, x_t, x_content, t, style_id):
        """
        Args:
            x_t: [B, 4, H, W] - å½“å‰ Flow çŠ¶æ€
            x_content: [B, 4, H, W] - åŸå›¾ Latent
            t: [B] æˆ– [B, 1] - æ—¶é—´æ­¥ (0~1)
            style_id: [B] - é£æ ¼ ID (0~N æˆ– null_class_id)
        """
        # 1. æ—¶é—´åµŒå…¥
        if t.dim() == 1:
            t = t.view(-1, 1)
        t_emb = self.time_embed(t.squeeze(-1))  # [B, dim]
        
        # 2. é£æ ¼åµŒå…¥
        s_emb = self.style_embed(style_id)  # [B, dim]
        
        # 3. ğŸŸ¢ å…¨å±€æ¡ä»¶èåˆ
        global_cond = t_emb + s_emb
        
        # 4. ç¼–ç å†…å®¹
        x_cond = self.content_encoder(x_content)
        
        # 5. è¾“å…¥æŠ•å½±
        x = self.stem(x_t)
        
        # 6. ä¸»å¹²ç½‘ç»œï¼ˆæ¯ä¸€å±‚éƒ½æ³¨å…¥æ¡ä»¶ï¼‰
        for block in self.blocks:
            x = block(x, x_cond, global_cond, t_emb)
        
        # 7. è¾“å‡ºé€Ÿåº¦åœº
        x = self.final_norm(x)
        v = self.final(x)
        
        return v