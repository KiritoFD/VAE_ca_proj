import sys
import os
import torch
import gc
import time
from pathlib import Path
from train import LSFMTrainer

# ğŸŸ¢ æ–°å¢ï¼šå¯¼å…¥è¯„ä¼°æ¨¡å—
from eval_lpips import Evaluator as LPIPSEvaluator
from eval_clip import Evaluator as CLIPEvaluator
from eval_vgg import Evaluator as VGGEvaluator

# ==============================================================================
# ğŸ›ï¸ å®éªŒé…ç½®ä¸­å¿ƒ
# è¿™é‡Œåˆ—å‡ºçš„æ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒä»»åŠ¡ã€‚
# å­—å…¸ä¸­çš„ç»“æ„ä¸ config.json å®Œå…¨ä¸€è‡´ï¼Œæœªåˆ—å‡ºçš„å‚æ•°å°†ä½¿ç”¨ config.json çš„é»˜è®¤å€¼ã€‚
# ==============================================================================

EXPERIMENTS = [
    # --- å®éªŒ 1: åŸºå‡†å¯¹ç…§ç»„ (å¤§ç«æ…¢ç‚–) ---
    {
        "name": "Exp1_Baseline_LR1e4_W5",
        "description": "æ ‡å‡† LRï¼Œæƒé‡ 5ï¼Œè·‘ 100 è½®çœ‹æ”¶æ•›",
        "training": {
            "learning_rate": 1e-4,
            "transfer_loss_weight": 5.0,
            "stage1_epochs": 100,
            "batch_size": 64
        }
    },
    
    # --- å®éªŒ 2: æ¿€è¿›æƒé‡ç»„ (å¼ºè¿«ç—‡æ¨¡å¼) ---
    {
        "name": "Exp2_HighWeight_W20",
        "description": "æå¤§å¢åŠ è½¬æ¢æƒé‡ï¼Œçœ‹æ˜¯å¦èƒ½äº§ç”Ÿæ›´å¼ºçƒˆçš„é£æ ¼",
        "training": {
            "learning_rate": 8e-5,
            "transfer_loss_weight": 20.0,
            "stage1_epochs": 100,
        }
    },

    # --- å®éªŒ 3: å°ç«æ…¢ç‚– (ç»†èŠ‚æ‰“ç£¨) ---
    {
        "name": "Exp3_LowLR_LongRun",
        "description": "æä½ LRï¼Œè·‘ä¹…ä¸€ç‚¹ï¼Œé˜²æ­¢é”™è¿‡æœ€ä¼˜è§£",
        "training": {
            "learning_rate": 2e-5,
            "transfer_loss_weight": 15.0,
            "stage1_epochs": 200,
        }
    },
    
    # --- å®éªŒ 4: ç”šè‡³å¯ä»¥æ”¹æ¨¡å‹å‚æ•° (å¦‚æœæ˜¾å­˜å…è®¸) ---
    # {
    #     "name": "Exp4_DeeperModel",
    #     "model": {
    #         "depth": 10,
    #         "dim": 768
    #     },
    #     "training": {
    #         "batch_size": 32
    #     }
    # }
]

# ==============================================================================
# ğŸŸ¢ æ–°å¢ï¼šè¯„ä¼°å‡½æ•°
# ==============================================================================
def run_evaluations(ckpt_path, exp_name, config_path="config.json"):
    """
    è¿è¡Œæ‰€æœ‰ä¸‰ä¸ªè¯„ä¼°è„šæœ¬å¹¶è®°å½•ç»“æœ
    """
    import json
    
    print("\n" + "="*60)
    print(f"ğŸ“Š Running Evaluations for: {exp_name}")
    print("="*60)
    
    # è¯»å–é…ç½®è·å–å‚è€ƒç›®å½•
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)
    
    ref_dir = cfg.get("data", {}).get("data_root", None)
    if ref_dir:
        ref_dir = ref_dir.strip('"').strip("'")
    
    results = {}
    
    # 1. LPIPS Evaluation
    try:
        print("\nğŸ”¹ [1/3] Running LPIPS Evaluation...")
        lpips_eval = LPIPSEvaluator(str(ckpt_path), config_path)
        target_dir = cfg.get("inference", {}).get("image_path", "").strip('"').strip("'")
        if target_dir:
            lpips_eval.evaluate(target_dir, batch_size=2)
        del lpips_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… LPIPS Evaluation Complete")
    except Exception as e:
        print(f"âŒ LPIPS Evaluation Failed: {e}")
    
    # 2. CLIP Evaluation
    try:
        print("\nğŸ”¹ [2/3] Running CLIP Evaluation...")
        clip_eval = CLIPEvaluator(str(ckpt_path), config_path)
        target_dir = cfg.get("inference", {}).get("image_path", "").strip('"').strip("'")
        if target_dir:
            clip_eval.evaluate(target_dir, batch_size=2)
        del clip_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… CLIP Evaluation Complete")
    except Exception as e:
        print(f"âŒ CLIP Evaluation Failed: {e}")
    
    # 3. VGG Style Evaluation
    try:
        print("\nğŸ”¹ [3/3] Running VGG Style Evaluation...")
        vgg_eval = VGGEvaluator(str(ckpt_path), ref_root=ref_dir, config_path=config_path)
        vgg_eval.evaluate(bs=1)
        del vgg_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… VGG Evaluation Complete")
    except Exception as e:
        print(f"âŒ VGG Evaluation Failed: {e}")
    
    print("\n" + "="*60)
    print(f"ğŸ“Š All Evaluations Finished for: {exp_name}")
    print("="*60)

# ==============================================================================
# è‡ªåŠ¨åŒ–å¼•æ“ (Auto-Pilot)
# ==============================================================================
def run_grid_search():
    # ç»“æœæ€»æ ¹ç›®å½•
    ROOT_SAVE_DIR = Path("AutoSearch_Results")
    ROOT_SAVE_DIR.mkdir(exist_ok=True)
    
    print(f"ğŸš€ Starting Grid Search: {len(EXPERIMENTS)} Experiments Queued.")
    print(f"ğŸ“‚ Root Output: {ROOT_SAVE_DIR.absolute()}")

    for i, exp in enumerate(EXPERIMENTS):
        exp_name = exp['name']
        print("\n" + "#"*60)
        print(f"â–¶ï¸  [{i+1}/{len(EXPERIMENTS)}] Running Experiment: {exp_name}")
        print(f"â„¹ï¸  Description: {exp.get('description', 'N/A')}")
        print("#"*60)

        # 1. æ„é€ æœ¬æ¬¡å®éªŒçš„ä¸“å±ç›®å½•
        exp_dir = ROOT_SAVE_DIR / exp_name
        ckpt_dir = exp_dir / "checkpoints"
        vis_dir = exp_dir / "visualizations"
        
        # 2. æ„é€ é…ç½®è¦†ç›– (Override)
        config_override = {
            "checkpoint": {
                "save_dir": str(ckpt_dir)
            },
            "inference": {
                "save_dir": str(vis_dir),
                "num_inference_steps": 4 
            }
        }
        
        # å°†ç”¨æˆ·å®šä¹‰çš„å‚æ•°åˆå¹¶è¿›å» (training, model, data ç­‰)
        for k, v in exp.items():
            if k not in ["name", "description"]:
                config_override[k] = v

        start_time = time.time()
        trainer = None

        try:
            # 3. å®ä¾‹åŒ–è®­ç»ƒå™¨ (ä¼ å…¥è¦†ç›–å‚æ•°)
            trainer = LSFMTrainer(config_override=config_override)
            
            # 4. è¿è¡Œè®­ç»ƒ (åªè·‘ Stage 1 å³å¯å¿«é€ŸéªŒè¯é£æ ¼)
            trainer.run_stage1()
            
            # 5. å¼ºåˆ¶æ‰§è¡Œä¸€æ¬¡æœ€ç»ˆæ¨ç†
            print("ğŸ¨ Running Final Inference...")
            final_model = trainer.get_model()
            final_ckpt = trainer.ckpt_dir / "stage1_final.pt"
            if final_ckpt.exists():
                trainer.safe_load(final_model, torch.load(final_ckpt))
                trainer.do_inference(final_model, "final", "stage1_final")
            
            print(f"âœ… Experiment [{exp_name}] Training Completed in {(time.time() - start_time)/60:.1f} mins.")
            
            # ğŸŸ¢ 6. è¿è¡Œè¯„ä¼°è„šæœ¬
            if final_ckpt.exists():
                # å…ˆæ¸…ç†è®­ç»ƒå™¨é‡Šæ”¾æ˜¾å­˜
                del trainer
                del final_model
                gc.collect()
                torch.cuda.empty_cache()
                trainer = None  # æ ‡è®°å·²åˆ é™¤
                
                run_evaluations(final_ckpt, exp_name)

        except KeyboardInterrupt:
            print("\nğŸ›‘ User Interrupted. Exiting...")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ Experiment [{exp_name}] Failed!")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # 7. æ˜¾å­˜æ¸…ç† (è‡³å…³é‡è¦)
            if trainer:
                del trainer
            gc.collect()
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU Memory Cleared.")

    print("\n" + "="*60)
    print("ğŸ‰ All Experiments Finished!")
    print("="*60)

if __name__ == "__main__":
    run_grid_search()
