import torch
from torch.utils.data import Dataset
from pathlib import Path
import os
import numpy as np
from PIL import Image
from torchvision import transforms

class Stage1Dataset(Dataset):
    """
    Stage 1 æ•°æ®é›†: é€šç”¨åŠ è½½å™¨
    èƒ½è¯»å–ï¼š
    1. é¢„å¤„ç†å¥½çš„ Latents (.npy / .pt) -> è®­ç»ƒæå¿«ï¼ŒIOå‹åŠ›å°
    2. åŸå§‹å›¾ç‰‡ (.jpg / .png) -> è®­ç»ƒæ—¶å®æ—¶ Encodeï¼ŒIOå‹åŠ›å¤§
    """
    def __init__(self, root_dir, num_classes):
        self.root = Path(root_dir)
        if not self.root.exists():
            raise FileNotFoundError(f"âŒ [Dataset] è·¯å¾„ä¸å­˜åœ¨: {self.root}")

        # 1. å®šä¹‰ç±»åˆ«æ˜ å°„
        # è‡ªåŠ¨æ‰«æå­ç›®å½•
        subdirs = sorted([d.name for d in self.root.iterdir() if d.is_dir()])
        
        # é»˜è®¤æ˜ å°„è¡¨ï¼Œå¦‚æœä½ çš„æ–‡ä»¶å¤¹å« trainA/trainBï¼Œä¼šè‡ªåŠ¨åŒ¹é…
        # å¦‚æœä½ çš„æ–‡ä»¶å¤¹å« class0/class1ï¼Œä¹Ÿä¼šè‡ªåŠ¨åŒ¹é…
        self.class_map = {
            'trainA': 0, 'testA': 0, 'class0': 0, 'A': 0, 'monet': 0, 'photo': 1,
            'trainB': 1, 'testB': 1, 'class1': 1, 'B': 1, 'art': 0
        }
        
        self.all_files = [] # list of (path, class_id)
        self.files_by_class = {} # dict {class_id: [paths]}

        print(f"ğŸ” [Dataset] Scanning {self.root}...")
        
        # 2. éå†ç›®å½•
        found_any = False
        for d in self.root.iterdir():
            if not d.is_dir(): continue
            
            # ç¡®å®šç±»åˆ« ID
            cid = -1
            if d.name in self.class_map:
                cid = self.class_map[d.name]
            else:
                # å¦‚æœæ–‡ä»¶å¤¹åå­—ä¸åœ¨æ˜ å°„è¡¨é‡Œï¼Œå°è¯•æŒ‰å­—æ¯é¡ºåºåˆ†é…
                # è¿™åªæ˜¯ä¸€ä¸ªå…œåº•ç­–ç•¥
                pass
            
            if cid == -1: continue # è·³è¿‡æœªçŸ¥æ–‡ä»¶å¤¹

            if cid not in self.files_by_class:
                self.files_by_class[cid] = []

            # 3. æ ¸å¿ƒä¿®å¤ï¼šé€’å½’æœç´¢æ‰€æœ‰å¯èƒ½çš„åç¼€
            # ä½¿ç”¨ rglob (recursive glob) é˜²æ­¢æ–‡ä»¶åœ¨å­æ–‡ä»¶å¤¹é‡Œ
            extensions = ['*.npy', '*.pt', '*.jpg', '*.jpeg', '*.png', '*.bmp']
            files = []
            for ext in extensions:
                # case-insensitive search on Windows usually works with glob, 
                # but rglob is safer for nested structures
                files.extend(list(d.rglob(ext)))
                # å°è¯•å¤§å†™åç¼€
                files.extend(list(d.rglob(ext.upper())))
            
            # å»é‡ (é˜²æ­¢å¤§å°å†™é‡å¤åŒ¹é…)
            files = sorted(list(set(files)))
            
            for f in files:
                self.all_files.append((f, cid))
                self.files_by_class[cid].append(f)
            
            if len(files) > 0:
                print(f"   ğŸ“‚ Found Class {cid} ({d.name}): {len(files)} files")
                found_any = True
        
        if not found_any:
            print(f"âš ï¸ [Dataset] è­¦å‘Š: åœ¨ {self.root} ä¸‹æ‰¾åˆ°äº†æ–‡ä»¶å¤¹ {subdirs}ï¼Œä½†æ²¡æ‰¾åˆ°ä»»ä½•æ–‡ä»¶ï¼")
            print(f"   è¯·æ£€æŸ¥: 1. æ–‡ä»¶å¤¹å†…æ˜¯å¦æœ‰ .npy/.jpg æ–‡ä»¶ï¼Ÿ")
            print(f"           2. æ–‡ä»¶å¤¹åæ˜¯å¦æ˜¯ trainA/trainBï¼Ÿ")
        else:
            print(f"âœ… [Dataset] Stage 1 åŠ è½½å®Œæˆã€‚æ€»æ•°: {len(self.all_files)}")

        # é¢„å®šä¹‰ Transform (ä»…å½“è¯»å–å›¾ç‰‡æ—¶ä½¿ç”¨)
        self.transform = transforms.Compose([
            transforms.Resize(512), 
            transforms.CenterCrop(512),
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])

    def load_latent(self, path):
        """æ™ºèƒ½åŠ è½½å‡½æ•°"""
        path = Path(path)
        ext = path.suffix.lower()
        
        if ext == '.npy':
            # åŠ è½½ Numpy æ ¼å¼ Latent
            arr = np.load(path)
            return torch.from_numpy(arr)
            
        elif ext == '.pt':
            # åŠ è½½ PyTorch æ ¼å¼ Latent
            return torch.load(path)
            
        elif ext in ['.jpg', '.png', '.jpeg', '.bmp']:
            # åŠ è½½åŸå§‹å›¾ç‰‡ -> è½¬æ¢æˆ Tensor
            # æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯ Pixel Tensor [3, 512, 512]
            # åœ¨ train.py é‡Œï¼Œå¦‚æœæ˜¯ Pixelï¼Œéœ€è¦ VAE Encode
            # ä½†ä¸ºäº†ç»Ÿä¸€æ¥å£ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå‡è®¾ train.py ä¼šå¤„ç† encodeï¼Œæˆ–è€…æˆ‘ä»¬åœ¨è¿™é‡Œæ— æ³• encode (æ²¡æœ‰ vae)
            # é€šå¸¸æˆ‘ä»¬åœ¨ dataset é‡Œåªè¿”å› tensorã€‚
            # âš ï¸ é‡è¦: å¦‚æœä½ çš„ train.py æœŸæœ›ç›´æ¥æ‹¿åˆ° latentï¼Œè¿™é‡Œè¯»å–å›¾ç‰‡ä¼šå¯¼è‡´å½¢çŠ¶ä¸å¯¹ã€‚
            # æ—¢ç„¶ä½ æŒ‡å‘äº† latents æ–‡ä»¶å¤¹ï¼Œè¯´æ˜ä½ ä¸»è¦æ˜¯æƒ³è¯» .npyã€‚
            # å¦‚æœè¯»åˆ°äº†å›¾ç‰‡ï¼Œdo_inference é‡Œçš„ vae.decode ä¼šå‡ºé”™ï¼ˆå› ä¸ºè¾“å…¥å·²ç»æ˜¯ pixelï¼‰ã€‚
            
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿™é‡Œè¿”å› Pixel Tensorã€‚
            # train.py éœ€è¦åˆ¤æ–­ï¼šå¦‚æœè¾“å…¥æ˜¯ [4, 64, 64] -> Latent
            # å¦‚æœè¾“å…¥æ˜¯ [3, 512, 512] -> Pixel -> éœ€è¦ VAE Encode
            img = Image.open(path).convert("RGB")
            return self.transform(img)
            
        else:
            raise ValueError(f"Unsupported file type: {ext}")

    def __len__(self):
        return len(self.all_files)

    def __getitem__(self, idx):
        path_c, cls_c = self.all_files[idx]
        
        # 1. åŠ è½½ Content
        x_c = self.load_latent(path_c)
        
        # 2. éšæœºé‡‡æ · Style
        target_cls = np.random.choice(list(self.files_by_class.keys()))
        if len(self.files_by_class[target_cls]) > 0:
            path_s = np.random.choice(self.files_by_class[target_cls])
            x_s = self.load_latent(path_s)
        else:
            # Fallback (æå°‘è§æƒ…å†µ)
            x_s = x_c.clone()
        
        return x_c, x_s, torch.tensor(target_cls), torch.tensor(cls_c)


class Stage2Dataset(Dataset):
    """
    Stage 2 æ•°æ®é›†: è¯»å– Reflow ç”Ÿæˆçš„ .pt é…å¯¹æ•°æ®
    """
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.pt_files = sorted(list(self.data_dir.glob("*.pt")))
        
        if len(self.pt_files) == 0:
            print(f"âŒ [Dataset] åœ¨ {self.data_dir} ä¸‹æœªæ‰¾åˆ° .pt æ–‡ä»¶ï¼")
            self.indices = []
            return

        print(f"ğŸ” [Dataset] ç´¢å¼• Stage 2 æ•°æ® ({len(self.pt_files)} æ–‡ä»¶)...")
        
        self.indices = [] 
        # å¿«é€Ÿç´¢å¼•
        for i, pt_file in enumerate(self.pt_files):
            try:
                # è¯»å– header ä»¥è·å– batch size (é€šå¸¸æ–‡ä»¶åé‡Œä¸å¸¦ä¿¡æ¯ï¼Œéœ€è¯»å–)
                # ä¸ºäº†é€Ÿåº¦ï¼Œå‡è®¾æ‰€æœ‰ batch size ä¸€æ ·ï¼Œæˆ–è€…åªè¯»ç¬¬ä¸€ä¸ª
                # è¿™é‡Œä¸ºäº†ç¨³å¥ï¼Œç®€å•éå†ä¸€æ¬¡ï¼ˆå¾ˆå¿«ï¼‰
                # ä¼˜åŒ–: å‡è®¾æ¯ä¸ªæ–‡ä»¶ batch size = training batch size (e.g. 4)
                # åªæœ‰æœ€åä¸€ä¸ªæ–‡ä»¶å¯èƒ½å°ã€‚
                # æ­£ç¡®åšæ³•ï¼šè¯»å–æ–‡ä»¶è·å–å¤§å°
                data = torch.load(pt_file, map_location="cpu")
                bs = data['z0'].size(0)
                for j in range(bs):
                    self.indices.append((i, j))
            except:
                pass
                
        print(f"âœ… [Dataset] Stage 2 åŠ è½½å®Œæˆã€‚æ ·æœ¬æ•°: {len(self.indices)}")
        
        self.current_file_idx = -1
        self.current_data = None

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        file_idx, row_idx = self.indices[idx]
        
        if file_idx != self.current_file_idx:
            self.current_data = torch.load(self.pt_files[file_idx], map_location="cpu")
            self.current_file_idx = file_idx
            
        z0 = self.current_data['z0'][row_idx]
        z1 = self.current_data['z1'][row_idx]
        t_id = self.current_data['t_id'][row_idx]
        
        return z0, z1, t_id