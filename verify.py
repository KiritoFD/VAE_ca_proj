import torch
import matplotlib.pyplot as plt
from pathlib import Path
from diffusers import AutoencoderKL
import json
import os

# 1. åŠ è½½é…ç½®
with open("config.json", 'r') as f:
    cfg = json.load(f)

reflow_dir = Path(cfg['training']['reflow_data_dir'])
device = "cuda" if torch.cuda.is_available() else "cpu"

# 2. åŠ è½½ VAE
print("Loading VAE...")
vae = AutoencoderKL.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="vae").to(device)

# 3. éšä¾¿æ‰¾ä¸€ä¸ª .pt æ–‡ä»¶
pt_files = list(reflow_dir.glob("*.pt"))
if not pt_files:
    print("âŒ é”™è¯¯ï¼šç¼“å­˜æ–‡ä»¶å¤¹æ˜¯ç©ºçš„ï¼")
    exit()

print(f"ğŸ” å‘ç° {len(pt_files)} ä¸ªç¼“å­˜æ–‡ä»¶ã€‚æ­£åœ¨æ£€æŸ¥ç¬¬ä¸€ä¸ªï¼š{pt_files[0]}")
data = torch.load(pt_files[0], map_location=device)

x_content = data['content'].unsqueeze(0)
z_target = data['z'].unsqueeze(0)

# 4. è§£ç çœ‹å›¾
def decode(latents):
    latents = latents / 0.18215
    imgs = vae.decode(latents).sample
    imgs = (imgs / 2 + 0.5).clamp(0, 1)
    return imgs.cpu().permute(0, 2, 3, 1).detach().numpy()[0]

img_c = decode(x_content)
img_z = decode(z_target)

# 5. æ˜¾ç¤ºå¯¹æ¯”
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Input (Content)")
plt.imshow(img_c)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Target (Generated by Stage 1)")
plt.imshow(img_z)
plt.axis('off')

plt.show()