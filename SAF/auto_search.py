import sys
import os
import torch
import gc
import time
import json
from pathlib import Path

# ğŸŸ¢ ä¿®æ”¹ï¼šå¯¼å…¥æ–°çš„è®­ç»ƒå™¨
sys.path.append(str(Path(__file__).parent.parent))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
from train import OTCFMTrainer, LatentDataset, create_model
from torch.utils.data import DataLoader

# ğŸŸ¢ æ–°å¢ï¼šå¯¼å…¥è¯„ä¼°æ¨¡å—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from eval_lpips import Evaluator as LPIPSEvaluator
    LPIPS_AVAILABLE = True
except ImportError:
    LPIPS_AVAILABLE = False
    print("âš ï¸  LPIPS Evaluator not found, skipping LPIPS evaluation")

try:
    from eval_clip import Evaluator as CLIPEvaluator
    CLIP_AVAILABLE = True
except ImportError:
    CLIP_AVAILABLE = False
    print("âš ï¸  CLIP Evaluator not found, skipping CLIP evaluation")

try:
    from eval_vgg import Evaluator as VGGEvaluator
    VGG_AVAILABLE = True
except ImportError:
    VGG_AVAILABLE = False
    print("âš ï¸  VGG Evaluator not found, skipping VGG evaluation")

# ==============================================================================
# ğŸ›ï¸ å®éªŒé…ç½®ä¸­å¿ƒ
# è¿™é‡Œåˆ—å‡ºçš„æ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒä»»åŠ¡ã€‚
# å­—å…¸ä¸­çš„ç»“æ„ä¸ config.json å®Œå…¨ä¸€è‡´ï¼Œæœªåˆ—å‡ºçš„å‚æ•°å°†ä½¿ç”¨ config.json çš„é»˜è®¤å€¼ã€‚
# ==============================================================================

EXPERIMENTS = [
    
    # -------------------------------------------------------------------------
    # ç¬¬ä¸€ç»„ï¼šåŸºå‡† (Baseline)
    # -------------------------------------------------------------------------
    {
        "name": "Exp1_Baseline",
        "description": "ã€åŸºå‡†çº¿ã€‘å„é¡¹å‚æ•°ä¸­åº¸ï¼Œç”¨äºå¯¹æ¯”å…¶ä»–å®éªŒçš„æå‡å¹…åº¦ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "label_drop_prob": 0.10,
            "stage1_epochs": 100,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬äºŒç»„ï¼šæ¿€è¿›å­¦ä¹ ç‡ (Aggressive LR)
    # éªŒè¯ï¼šæ›´å¿«çš„æ”¶æ•›æ˜¯å¦èƒ½ä¿æŒé£æ ¼è´¨é‡
    # -------------------------------------------------------------------------
    {
        "name": "Exp2_HighLR",
        "description": "ã€é«˜å­¦ä¹ ç‡ã€‘2å€LRï¼Œæµ‹è¯•å¿«é€Ÿæ”¶æ•›æ˜¯å¦å½±å“é£æ ¼è´¨é‡ã€‚",
        "training": {
            "learning_rate": 2e-4,
            "label_drop_prob": 0.10,
            "stage1_epochs": 120,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬ä¸‰ç»„ï¼šç²¾ç»†æ‰“ç£¨ (Precision Mode) - é‡ç‚¹å…³æ³¨ï¼
    # éªŒè¯ï¼šæ›´å°çš„å­¦ä¹ ç‡å’Œæ›´å¤šepochæ˜¯å¦æå‡ç”Ÿæˆè´¨é‡
    # -------------------------------------------------------------------------
    {
        "name": "Exp3_SlowCook",
        "description": "ã€æ…¢å·¥ç»†æ´»ã€‘æä½LR + é•¿Epochã€‚æ—¨åœ¨æå‡ç”Ÿæˆè´¨é‡ã€‚",
        "training": {
            "learning_rate": 2e-5,
            "label_drop_prob": 0.05,  # æ›´å°‘çš„label dropping
            "stage1_epochs": 300,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬å››ç»„ï¼šé«˜CFG dropout (Strong Unconditional)
    # éªŒè¯ï¼šæ›´å¼ºçš„CFGè®­ç»ƒæ˜¯å¦æå‡æ¨ç†æ—¶çš„æ§åˆ¶åŠ›
    # -------------------------------------------------------------------------
    {
        "name": "Exp4_HighDropout",
        "description": "ã€å¼ºCFGè®­ç»ƒã€‘20%æ¦‚ç‡ä½¿ç”¨å¹³å‡é£æ ¼åµŒå…¥ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "label_drop_prob": 0.20,
            "stage1_epochs": 150,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬äº”ç»„ï¼šåŠ¨æ€epsilonå…³é—­ (Static Epsilon)
    # éªŒè¯ï¼šå›ºå®šepsilonæ˜¯å¦å½±å“è®­ç»ƒç¨³å®šæ€§
    # -------------------------------------------------------------------------
    {
        "name": "Exp5_StaticEpsilon",
        "description": "ã€å›ºå®šepsilonã€‘å…³é—­åŠ¨æ€epsilonï¼Œæµ‹è¯•å¯¹è®­ç»ƒçš„å½±å“ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "label_drop_prob": 0.10,
            "dynamic_epsilon": False,
            "stage1_epochs": 100,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬å…­ç»„ï¼šå¤§Batch Size (High Stability)
    # éªŒè¯ï¼šæ›´å¤§çš„batch sizeæ˜¯å¦å¸¦æ¥æ›´ç¨³å®šçš„æ¢¯åº¦
    # æ³¨æ„ï¼šéœ€è¦æ ¹æ®æ˜¾å­˜è°ƒæ•´
    # -------------------------------------------------------------------------
    {
        "name": "Exp6_HighBS",
        "description": "ã€é«˜ç¨³å®šæ€§ã€‘å¤§Batch Sizeï¼Œæ¢¯åº¦ä¼°è®¡æ›´å‡†ç¡®ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "batch_size": 32,  # æ ¹æ®8Gæ˜¾å­˜è°ƒæ•´
            "label_drop_prob": 0.10,
            "stage1_epochs": 120,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬ä¸ƒç»„ï¼šå¿«é€Ÿepsiloné¢„çƒ­ (Fast Warmup)
    # éªŒè¯ï¼šæ›´å¿«è¾¾åˆ°ç›´çº¿è·¯å¾„æ˜¯å¦åŠ é€Ÿæ”¶æ•›
    # -------------------------------------------------------------------------
    {
        "name": "Exp7_FastWarmup",
        "description": "ã€å¿«é€Ÿé¢„çƒ­ã€‘50 epochè¾¾åˆ°æœ€å¤§epsilonã€‚",
        "training": {
            "learning_rate": 1e-4,
            "label_drop_prob": 0.10,
            "epsilon_warmup_epochs": 50,
            "stage1_epochs": 100,
        }
    }
]

# ==============================================================================
# ğŸŸ¢ ä¿®æ”¹ï¼šè¯„ä¼°å‡½æ•° - ç»Ÿä¸€è¾“å‡ºåˆ°å®éªŒç›®å½•
# ==============================================================================
def run_evaluations(ckpt_path, exp_name, exp_ckpt_dir, config_path="config.json"):
    """
    è¿è¡Œæ‰€æœ‰ä¸‰ä¸ªè¯„ä¼°è„šæœ¬å¹¶è®°å½•ç»“æœ
    æ‰€æœ‰è¯„ä¼°ç»“æœç»Ÿä¸€ä¿å­˜åˆ° exp_ckpt_dir/evaluation/ ä¸‹
    """
    eval_dir = Path(exp_ckpt_dir) / "evaluation"
    eval_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š Running Evaluations for: {exp_name}")
    print(f"ğŸ“‚ Results will be saved to: {eval_dir}")
    print("="*60)
    
    # è¯»å–é…ç½®è·å–å‚è€ƒç›®å½•
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)
    
    ref_dir = cfg.get("data", {}).get("raw_data_root", None)
    target_dir = cfg.get("inference", {}).get("image_path", "")
    
    # ğŸŸ¢ æ±‡æ€»ç»“æœå­—å…¸
    results_summary = {
        "experiment_name": exp_name,
        "checkpoint_path": str(ckpt_path),
        "evaluation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "metrics": {}
    }
    
    # 1. LPIPS Evaluation
    if LPIPS_AVAILABLE:
        try:
            print("\nğŸ”¹ [1/3] Running LPIPS Evaluation...")
            if not target_dir:
                raise ValueError("Target directory not configured in config.json")
            lpips_eval = LPIPSEvaluator(str(ckpt_path), config_path)
            lpips_results = lpips_eval.evaluate(target_dir, batch_size=2, save_dir=str(eval_dir))
            results_summary["metrics"]["lpips"] = lpips_results
            del lpips_eval
            gc.collect()
            torch.cuda.empty_cache()
            print("âœ… LPIPS Evaluation Complete")
        except Exception as e:
            print(f"âŒ LPIPS Evaluation Failed: {e}")
            results_summary["metrics"]["lpips"] = {"error": str(e)}
    
    # 2. CLIP Evaluation
    if CLIP_AVAILABLE:
        try:
            print("\nğŸ”¹ [2/3] Running CLIP Evaluation...")
            if not target_dir:
                raise ValueError("Target directory not configured in config.json")
            clip_eval = CLIPEvaluator(str(ckpt_path), config_path)
            clip_results = clip_eval.evaluate(target_dir, batch_size=2, save_dir=str(eval_dir))
            results_summary["metrics"]["clip"] = clip_results
            del clip_eval
            gc.collect()
            torch.cuda.empty_cache()
            print("âœ… CLIP Evaluation Complete")
        except Exception as e:
            print(f"âŒ CLIP Evaluation Failed: {e}")
            results_summary["metrics"]["clip"] = {"error": str(e)}
    
    # 3. VGG Style Evaluation
    if VGG_AVAILABLE:
        try:
            print("\nğŸ”¹ [3/3] Running VGG Style Evaluation...")
            vgg_eval = VGGEvaluator(str(ckpt_path), ref_root=ref_dir, config_path=config_path)
            vgg_results = vgg_eval.evaluate(bs=1, save_dir=str(eval_dir))
            results_summary["metrics"]["vgg"] = vgg_results
            del vgg_eval
            gc.collect()
            torch.cuda.empty_cache()
            print("âœ… VGG Evaluation Complete")
        except Exception as e:
            print(f"âŒ VGG Evaluation Failed: {e}")
            results_summary["metrics"]["vgg"] = {"error": str(e)}
    
    # ğŸŸ¢ ä¿å­˜æ±‡æ€»ç»“æœåˆ° JSON
    summary_path = eval_dir / "metrics_summary.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=4, ensure_ascii=False)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š All Evaluations Finished for: {exp_name}")
    print(f"ğŸ“„ Summary saved to: {summary_path}")
    print("="*60)
    
    return results_summary

# ==============================================================================
# ğŸŸ¢ æ–°å¢ï¼šåˆå¹¶é…ç½®çš„è¾…åŠ©å‡½æ•°
# ==============================================================================
def merge_config(base_config, override):
    """é€’å½’åˆå¹¶é…ç½®å­—å…¸"""
    result = base_config.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = merge_config(result[key], value)
        else:
            result[key] = value
    return result

# ==============================================================================
# è‡ªåŠ¨åŒ–å¼•æ“ (Auto-Pilot)
# ==============================================================================
def run_grid_search():
    # åŠ è½½åŸºç¡€é…ç½®
    base_config_path = Path(__file__).parent.parent / "config.json"
    with open(base_config_path, 'r', encoding='utf-8') as f:
        base_config = json.load(f)
    
    # ç»“æœæ€»æ ¹ç›®å½•
    ROOT_SAVE_DIR = Path("AutoSearch_Results")
    ROOT_SAVE_DIR.mkdir(exist_ok=True)
    
    print(f"ğŸš€ Starting Grid Search: {len(EXPERIMENTS)} Experiments Queued.")
    print(f"ğŸ“‚ Root Output: {ROOT_SAVE_DIR.absolute()}")

    for i, exp in enumerate(EXPERIMENTS):
        exp_name = exp['name']
        print("\n" + "#"*60)
        print(f"â–¶ï¸  [{i+1}/{len(EXPERIMENTS)}] Running Experiment: {exp_name}")
        print(f"â„¹ï¸  Description: {exp.get('description', 'N/A')}")
        print("#"*60)

        # 1. æ„é€ æœ¬æ¬¡å®éªŒçš„ä¸“å±ç›®å½•
        exp_dir = ROOT_SAVE_DIR / exp_name
        ckpt_dir = exp_dir / "checkpoints"
        ckpt_dir.mkdir(parents=True, exist_ok=True)
        
        # 2. æ„é€ é…ç½®è¦†ç›–
        config_override = merge_config(base_config, {
            "checkpoint": {
                "save_dir": str(ckpt_dir)
            }
        })
        
        # å°†ç”¨æˆ·å®šä¹‰çš„å‚æ•°åˆå¹¶è¿›å»
        for k, v in exp.items():
            if k not in ["name", "description"]:
                if k in config_override and isinstance(config_override[k], dict):
                    config_override[k] = merge_config(config_override[k], v)
                else:
                    config_override[k] = v
        
        # ä¿å­˜æœ¬æ¬¡å®éªŒçš„é…ç½®åˆ°æ–‡ä»¶
        exp_config_path = exp_dir / "experiment_config.json"
        with open(exp_config_path, 'w', encoding='utf-8') as f:
            json.dump(config_override, f, indent=4, ensure_ascii=False)
        print(f"ğŸ“ Experiment config saved to: {exp_config_path}")

        start_time = time.time()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        try:
            # 3. åˆ›å»ºæ•°æ®é›†å’ŒDataLoader
            print("\nğŸ“¦ Loading dataset...")
            dataset = LatentDataset(
                data_root=config_override['data']['data_root'],
                num_styles=config_override['data']['num_classes']
            )
            
            dataloader = DataLoader(
                dataset,
                batch_size=config_override['training']['batch_size'],
                shuffle=True,
                num_workers=config_override['training'].get('num_workers', 4),
                pin_memory=True,
                persistent_workers=True if config_override['training'].get('num_workers', 4) > 0 else False
            )
            
            # 4. åˆ›å»ºæ¨¡å‹
            print("\nğŸ—ï¸  Creating model...")
            model = create_model(config_override).to(device, memory_format=torch.channels_last)
            num_params = sum(p.numel() for p in model.parameters()) / 1e6
            print(f"Model parameters: {num_params:.2f}M")
            
            # 5. åˆ›å»ºè®­ç»ƒå™¨
            print("\nğŸš‚ Initializing trainer...")
            trainer = OTCFMTrainer(config_override, model, device)
            
            # 6. è¿è¡Œè®­ç»ƒ
            print("\nğŸ“ Starting training...")
            trainer.train(dataloader)
            
            print(f"âœ… Experiment [{exp_name}] Training Completed in {(time.time() - start_time)/60:.1f} mins.")
            
            # 7. è¿è¡Œè¯„ä¼°ï¼ˆå¦‚æœæœ‰æœ€ç»ˆcheckpointï¼‰
            final_ckpt = ckpt_dir / f"stage1_epoch{config_override['training']['stage1_epochs']}.pt"
            if not final_ckpt.exists():
                # å°è¯•æ‰¾æœ€æ–°çš„checkpoint
                ckpts = sorted(ckpt_dir.glob("stage1_epoch*.pt"))
                if ckpts:
                    final_ckpt = ckpts[-1]
            
            if final_ckpt.exists():
                print(f"\nğŸ“Š Using checkpoint: {final_ckpt.name}")
                # å…ˆæ¸…ç†è®­ç»ƒå™¨é‡Šæ”¾æ˜¾å­˜
                del trainer, model, dataloader, dataset
                gc.collect()
                torch.cuda.empty_cache()
                
                # è¿è¡Œè¯„ä¼°
                run_evaluations(final_ckpt, exp_name, ckpt_dir, str(exp_config_path))
            else:
                print("âš ï¸  No checkpoint found for evaluation")

        except KeyboardInterrupt:
            print("\nğŸ›‘ User Interrupted. Exiting...")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ Experiment [{exp_name}] Failed!")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # 8. æ˜¾å­˜æ¸…ç†
            gc.collect()
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU Memory Cleared.")

    print("\n" + "="*60)
    print("ğŸ‰ All Experiments Finished!")
    print(f"ğŸ“‚ Results saved to: {ROOT_SAVE_DIR.absolute()}")
    print("="*60)

if __name__ == "__main__":
    run_grid_search()
