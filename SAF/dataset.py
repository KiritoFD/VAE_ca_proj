import torch
from torch.utils.data import Dataset
from torchvision import transforms
from diffusers import AutoencoderKL
from pathlib import Path
import os
import json
import shutil
from tqdm import tqdm
from PIL import Image
import numpy as np

# ================= å¸¸é‡å®šä¹‰ =================
SCALING_FACTOR = 0.18215 

# ================= ç¬¬ä¸€éƒ¨åˆ†ï¼šé¢„å¤„ç†å·¥å…· =================
def preprocess_dataset(cfg, device='cuda'):
    """
    è¯»å– config -> éå† raw_data_root -> VAE ç¼–ç  -> ä¿å­˜åˆ° data_root
    """
    # 1. ä»é…ç½®è¯»å–è·¯å¾„
    src_root = Path(cfg['data']['raw_data_root'])
    dst_root = Path(cfg['data']['data_root'])
    
    if not src_root.exists():
        raise FileNotFoundError(f"âŒ [Config Error] åŸå§‹æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {src_root}")

    print(f"ğŸš€ [Preprocess] å¯åŠ¨é¢„å¤„ç†æµç¨‹")
    print(f"   ğŸ“‚ åŸå§‹å›¾ç‰‡: {src_root}")
    print(f"   ğŸ’¾ è¾“å‡ºç›®æ ‡: {dst_root}")

    # 2. å¼ºåˆ¶åŠ è½½ FT-MSE VAE (æ— å›é€€)
    print("   â³ æ­£åœ¨åŠ è½½ VAE: stabilityai/sd-vae-ft-mse ...")
    # å¦‚æœè¿™é‡ŒæŠ¥é”™ï¼Œè¯´æ˜ç¯å¢ƒé‡Œæ²¡ä¸‹è½½å¥½ï¼Œæˆ–è€…ç½‘ç»œä¸é€šï¼Œç›´æ¥è®©å®ƒæŠ›å‡ºå¼‚å¸¸ï¼Œä¸ç»™å›é€€æœºä¼š
    vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse").to(device)
    vae.eval()
    vae.requires_grad_(False)
    vae.float() # ä½¿ç”¨ FP32 ä¿è¯ç¼–ç ç²¾åº¦

    # 3. å®šä¹‰é¢„å¤„ç† (å‡è®¾å›¾ç‰‡å·²ç»æ˜¯ 256x256ï¼Œä¸åš Resize)
    img_transform = transforms.Compose([
        transforms.ToTensor(),             # [0, 255] -> [0.0, 1.0]
        transforms.Normalize([0.5], [0.5]) # [0.0, 1.0] -> [-1.0, 1.0]
    ])

    # 4. æ‰«æå¹¶å¤„ç†
    subdirs = [d for d in src_root.iterdir() if d.is_dir()]
    total_files = 0
    
    for subdir in subdirs:
        # åœ¨ç›®æ ‡ç›®å½•åˆ›å»ºåŒåå­æ–‡ä»¶å¤¹
        target_dir = dst_root / subdir.name
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # æ‰«æå¸¸è§å›¾ç‰‡æ ¼å¼
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        files = []
        for ext in extensions:
            files.extend(list(subdir.glob(ext)))
            files.extend(list(subdir.glob(ext.upper())))
        
        files = sorted(list(set(files)))
        print(f"   ğŸ‘‰ æ­£åœ¨å¤„ç†ç±»åˆ«ç›®å½•: {subdir.name} ({len(files)} å¼ )")

        for img_path in tqdm(files, desc=f"Encoding {subdir.name}"):
            save_path = target_dir / (img_path.stem + ".pt")
            
            # è·³è¿‡å·²å­˜åœ¨çš„ (æ”¯æŒæ–­ç‚¹ç»­ä¼ )
            if save_path.exists():
                continue

            try:
                # è¯»å–å›¾ç‰‡
                img = Image.open(img_path).convert("RGB")
                
                # ç®€å•æ ¡éªŒä¸€ä¸‹å°ºå¯¸ (å¯é€‰ï¼Œé˜²æ­¢æ··å…¥è„æ•°æ®)
                if img.size != (256, 256):
                    # å¦‚æœä½ éå¸¸ç¡®å®šå…¨æ˜¯256ï¼Œè¿™è¡Œå¯ä»¥æ³¨é‡Šæ‰ï¼›å¦åˆ™æœ€å¥½Resizeä¸€ä¸‹é˜²æ­¢æŠ¥é”™
                    img = img.resize((256, 256), Image.BICUBIC)

                # è½¬ Tensor
                pixel_tensor = img_transform(img).unsqueeze(0).to(device)
                
                # VAE ç¼–ç 
                with torch.no_grad():
                    # Encode -> Sample -> Scale
                    dist = vae.encode(pixel_tensor).latent_dist
                    latent = dist.sample() * SCALING_FACTOR
                
                # ä¿å­˜ä¸º [4, 32, 32] (CPU Tensor)
                torch.save(latent.squeeze(0).cpu(), save_path)
                total_files += 1
                
            except Exception as e:
                print(f"   âŒ [Error] {img_path.name}: {e}")

    print(f"âœ… [Preprocess] é¢„å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {total_files} ä¸ª Latent æ–‡ä»¶ã€‚")


# ================= ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é›†åŠ è½½å™¨ =================
class Stage1Dataset(Dataset):
    """
    è®­ç»ƒç”¨ Datasetï¼šåªè¯»å– data_root ä¸‹çš„ .pt æ–‡ä»¶
    """
    def __init__(self, data_root, num_classes=2):
        self.root = Path(data_root)
        if not self.root.exists():
            raise FileNotFoundError(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {self.root}\nğŸ‘‰ è¯·å…ˆè¿è¡Œ 'python src/dataset.py' è¿›è¡Œé¢„å¤„ç†ï¼")

        # ç¡¬ç¼–ç çš„ç±»åˆ«æ˜ å°„ï¼Œé€‚é… monet2photo
        self.class_map = {
            'trainA': 0, 'testA': 0, 'monet': 0, 
            'trainB': 1, 'testB': 1, 'photo': 1
        }
        
        self.all_files = [] 
        self.files_by_class = {} 

        print(f"ğŸ” [Dataset] æ‰«æ Latent æ•°æ®: {self.root}")
        
        # éå†å­æ–‡ä»¶å¤¹
        for d in self.root.iterdir():
            if not d.is_dir(): continue
            
            cid = self.class_map.get(d.name, -1)
            if cid == -1: continue 

            if cid not in self.files_by_class: 
                self.files_by_class[cid] = []

            # æ”¶é›† .pt æ–‡ä»¶
            files = sorted(list(d.glob("*.pt")))
            
            for f in files:
                self.all_files.append((f, cid))
                self.files_by_class[cid].append(f)
            
            if len(files) > 0:
                print(f"   ğŸ“‚ ç±»åˆ« {cid} ({d.name}): {len(files)} ä¸ªæ–‡ä»¶")

        if len(self.all_files) == 0:
            raise RuntimeError(f"âŒ åœ¨ {self.root} ä¸‹æœªæ‰¾åˆ° .pt æ–‡ä»¶ï¼\nè¯·æ£€æŸ¥ config.json ä¸­çš„ 'data_root' æ˜¯å¦æ­£ç¡®ï¼Œæˆ–æ˜¯å¦å·²è¿è¡Œé¢„å¤„ç†ã€‚")

    def __len__(self):
        return len(self.all_files)

    def __getitem__(self, idx):
        path_c, cls_c = self.all_files[idx]
        
        # 1. åŠ è½½ Content Latent [4, 32, 32]
        # weights_only=True æ˜¯æ–°ç‰ˆ PyTorch çš„å®‰å…¨å»ºè®®
        x_c = torch.load(path_c, map_location='cpu', weights_only=True)
        
        # 2. éšæœºé‡‡æ · Style Latent
        target_cls = np.random.choice(list(self.files_by_class.keys()))
        if len(self.files_by_class[target_cls]) > 0:
            path_s = np.random.choice(self.files_by_class[target_cls])
            x_s = torch.load(path_s, map_location='cpu', weights_only=True)
        else:
            x_s = x_c.clone()
        
        return x_c, x_s, torch.tensor(target_cls), torch.tensor(cls_c)


class Stage2Dataset(Dataset):
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.pt_files = sorted(list(self.data_dir.glob("*.pt")))
        self.indices = []
        
        if len(self.pt_files) > 0:
            print(f"ğŸ” [Dataset] Stage 2 ç´¢å¼• ({len(self.pt_files)} files)...")
            try:
                # è¯»å–é¦–ä¸ªæ–‡ä»¶æ¨æ–­ Batch Size
                data = torch.load(self.pt_files[0], map_location="cpu", weights_only=True)
                bs = data['z0'].size(0)
                for i in range(len(self.pt_files)):
                    for j in range(bs):
                        self.indices.append((i, j))
            except Exception as e:
                print(f"âš ï¸ [Dataset] ç´¢å¼•å‡ºé”™: {e}")

        self.current_file_idx = -1
        self.current_data = None

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        file_idx, row_idx = self.indices[idx]
        
        if file_idx != self.current_file_idx:
            self.current_data = torch.load(self.pt_files[file_idx], map_location="cpu", weights_only=True)
            self.current_file_idx = file_idx
        
        # ç®€å•è¶Šç•Œä¿æŠ¤
        if row_idx >= self.current_data['z0'].size(0): row_idx = 0
            
        z0 = self.current_data['z0'][row_idx]
        z1 = self.current_data['z1'][row_idx]
        t_id = self.current_data['t_id'][row_idx]
        return z0, z1, t_id


# ================= è„šæœ¬å…¥å£ =================
if __name__ == "__main__":
    # è¯»å–æ ¹ç›®å½•ä¸‹çš„ config.json
    config_path = Path("config.json")
    if not config_path.exists():
        # å°è¯•å‘ä¸Šæ‰¾ä¸€çº§ï¼Œé˜²æ­¢ç”¨æˆ·åœ¨ src ç›®å½•ä¸‹è¿è¡Œ
        config_path = Path("../config.json")
    
    if not config_path.exists():
        raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° config.jsonï¼Œè¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œæˆ–é…ç½®æ–‡ä»¶å­˜åœ¨ã€‚")

    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)

    # æ‰§è¡Œé¢„å¤„ç†
    preprocess_dataset(cfg)