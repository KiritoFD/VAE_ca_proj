#pip install onnx onnx-simplifier MNN
import torch
import torch.nn as nn
import os
import json
import numpy as np
import subprocess
from PIL import Image
from diffusers import AutoencoderKL
import onnx
from onnxsim import simplify

# å‡è®¾ SAFlow.py åœ¨åŒä¸€ç›®å½•ä¸‹ï¼Œå¦åˆ™è¯·è°ƒæ•´è·¯å¾„
try:
    from SAFlow import SAFModel
except ImportError:
    print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° SAFlow.pyï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹æˆ–åœ¨ PYTHONPATH ä¸­ã€‚")
    exit(1)

# ================= é…ç½® =================
CKPT_PATH = r"g:\GitHub\VAE_ca_proj\checkpoints\stage1_epoch10.pt"
OUTPUT_DIR = "./mnn_export_final"
CONFIG_PATH = "config.json"
TEST_IMG_PATH = "test.jpg"  # å¿…é¡»å­˜åœ¨ï¼Œç”¨äºç”Ÿæˆå‡†ç¡®çš„ Trace
OPSET_VERSION = 14          # Opset 14 å…¼å®¹æ€§è¾ƒå¥½
# =======================================

def load_config():
    if not os.path.exists(CONFIG_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_PATH}")
    with open(CONFIG_PATH, 'r') as f:
        return json.load(f)

# --- Wrappers (ä¿æŒä¸å˜) ---
class EncoderWrapper(nn.Module):
    def __init__(self, vae):
        super().__init__()
        self.vae = vae
    def forward(self, x):
        return self.vae.encode(x).latent_dist.mode() * 0.18215

class FlowWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
    def forward(self, x_t, x_cond, t, s):
        # ç¡®ä¿è¾“å…¥ç±»å‹åŒ¹é…ï¼Œé˜²æ­¢ ONNX ç±»å‹æ¨æ–­é”™è¯¯
        return self.model(x_t, x_cond, t, s)

class DecoderWrapper(nn.Module):
    def __init__(self, vae):
        super().__init__()
        self.vae = vae
    def forward(self, z):
        z = z / 0.18215
        out = self.vae.decode(z).sample
        out = (out / 2.0) + 0.5
        return torch.clamp(out, 0.0, 1.0)

def load_real_image(path):
    if not os.path.exists(path):
        print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° {path}ï¼Œä½¿ç”¨éšæœºå™ªå£°ä»£æ›¿ï¼ˆå¯èƒ½ä¼šå¯¼è‡´é‡åŒ–å±‚ç»Ÿè®¡ä¸å‡†ï¼‰ï¼")
        return torch.randn(1, 3, 512, 512)
    
    print(f"ğŸ“· è¯»å–æµ‹è¯•å›¾ç‰‡: {path}")
    img = Image.open(path).convert("RGB").resize((512, 512))
    img = np.array(img).astype(np.float32) / 127.5 - 1.0
    img = img.transpose(2, 0, 1)
    return torch.from_numpy(img).unsqueeze(0)

def onnx_simplify(onnx_path):
    """ ä½¿ç”¨ onnx-simplifier ç®€åŒ–æ¨¡å‹ """
    print(f"   Now Simplifying: {onnx_path} ...")
    try:
        model = onnx.load(onnx_path)
        model_sim, check = simplify(model)
        if not check:
            print("   âš ï¸ onnx-simplifier æ ¡éªŒå¤±è´¥ï¼Œè·³è¿‡ç®€åŒ–æ­¥éª¤")
            return
        onnx.save(model_sim, onnx_path)
        print("   âœ… Simplified.")
    except Exception as e:
        print(f"   âŒ Simplify å¤±è´¥: {e}")

def convert_to_mnn(onnx_path, mnn_path):
    """ è°ƒç”¨ MNNConvert å‘½ä»¤è¡Œå·¥å…· """
    print(f"   Now Converting to MNN: {mnn_path} ...")
    
    # æŒ‰ç…§ä½ çš„è¦æ±‚ï¼šä¸¥ç¦åŠ  --fp16
    # å¦‚æœæœªæ¥éœ€è¦ FP16ï¼ŒåŠ ä¸Š --fp16 å³å¯
    cmd = [
        "MNNConvert",
        "-f", "ONNX",
        "--modelFile", onnx_path,
        "--MNNModel", mnn_path,
        "--bizCode", "SAFlow",
        # "--fp16" # ä½ æ˜ç¡®è¦æ±‚ä¸åŠ 
    ]
    
    try:
        # Windows ä¸‹ shell=True æœ‰æ—¶èƒ½è§£å†³æ‰¾ä¸åˆ°å‘½ä»¤çš„é—®é¢˜ï¼ŒLinux ä¸‹é€šå¸¸ä¸éœ€è¦
        is_windows = os.name == 'nt'
        subprocess.check_call(cmd, shell=is_windows)
        print("   âœ… MNN Conversion Success.")
    except subprocess.CalledProcessError:
        print("   âŒ MNNConvert å¤±è´¥ï¼è¯·æ£€æŸ¥æ˜¯å¦å®‰è£…äº† MNN (pip install MNN) å¹¶ä¸”æ·»åŠ åˆ°äº†ç¯å¢ƒå˜é‡ã€‚")
    except FileNotFoundError:
        print("   âŒ æ‰¾ä¸åˆ° MNNConvert å‘½ä»¤ã€‚")

def export_pipeline():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    device = torch.device("cpu") # å¯¼å‡ºæ—¶å»ºè®®ç”¨ CPUï¼Œé¿å… CUDA ç®—å­å¸¦æ¥çš„å…¼å®¹æ€§é—®é¢˜
    
    print("1. åŠ è½½ PyTorch æ¨¡å‹...")
    cfg = load_config()
    
    saf_model = SAFModel(**cfg['model']).to(device)
    if os.path.exists(CKPT_PATH):
        print(f"   Load Checkpoint: {CKPT_PATH}")
        saf_model.load_state_dict(torch.load(CKPT_PATH, map_location=device))
    else:
        print(f"âš ï¸ Warning: Checkpoint not found at {CKPT_PATH}, using random weights.")
    saf_model.eval()
    
    print("   Load VAE...")
    vae = AutoencoderKL.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="vae").to(device)
    vae.eval()
    
    encoder = EncoderWrapper(vae).to(device)
    flow_net = FlowWrapper(saf_model).to(device)
    decoder = DecoderWrapper(vae).to(device)
    
    # ================= å‡†å¤‡è¾“å…¥æ•°æ® =================
    real_img_tensor = load_real_image(TEST_IMG_PATH).to(device)
    
    print("2. è®¡ç®—çœŸå® Latent ç”¨äº Flow è¾“å…¥...")
    with torch.no_grad():
        real_latent = encoder(real_img_tensor) # [1, 4, 64, 64]
    
    # æ ‡é‡è¾“å…¥
    dummy_t = torch.tensor([0.5]).float().to(device)
    dummy_s = torch.tensor([0]).int().to(device)

    # ================= å®šä¹‰å¯¼å‡ºä»»åŠ¡ =================
    tasks = [
        {
            "name": "Encoder",
            "model": encoder,
            "args": (real_img_tensor,),
            "input_names": ['input'],
            "output_names": ['output']
        },
        {
            "name": "Flow",
            "model": flow_net,
            "args": (real_latent, real_latent, dummy_t, dummy_s),
            "input_names": ['x_t', 'x_cond', 't', 's'],
            "output_names": ['output']
        },
        {
            "name": "Decoder",
            "model": decoder,
            "args": (real_latent,),
            "input_names": ['input'],
            "output_names": ['output']
        }
    ]

    # ================= å¾ªç¯æ‰§è¡Œå¯¼å‡º =================
    for task in tasks:
        name = task["name"]
        onnx_file = os.path.join(OUTPUT_DIR, f"{name}.onnx")
        mnn_file = os.path.join(OUTPUT_DIR, f"{name}.mnn")
        
        print(f"\n>>> å¤„ç† {name} ...")
        
        # 1. Torch -> ONNX
        torch.onnx.export(
            task["model"],
            task["args"],
            onnx_file,
            input_names=task["input_names"],
            output_names=task["output_names"],
            opset_version=OPSET_VERSION,
            do_constant_folding=True,
            keep_initializers_as_inputs=False,
            check_trace=False
        )
        
        # 2. Simplify ONNX
        onnx_simplify(onnx_file)
        
        # 3. ONNX -> MNN
        convert_to_mnn(onnx_file, mnn_file)

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æ–‡ä»¶ä½äº: {os.path.abspath(OUTPUT_DIR)}")

if __name__ == "__main__":
    with torch.no_grad():
        export_pipeline()