import torch
import os
import shutil
import numpy as np
from tqdm import tqdm
from diffusers import AutoencoderKL
from datasets import load_dataset
from PIL import Image
import json
from collections import defaultdict
from glob import glob

# ================= SD1.5 æ ‡å‡†é…ç½® =================
VAE_ID = "stabilityai/sd-vae-ft-mse"
IMG_SIZE = 512             # SD1.5 æ ‡å‡†å°ºå¯¸
SCALING_FACTOR = 0.18215   # SD1.5 æ ‡å‡†ç¼©æ”¾
SAVE_ROOT = "./wikiart_latents"
DEVICE = "cuda"
PROGRESS_FILE = os.path.join(SAVE_ROOT, "encode_progress.json")

# âŒ ç§»é™¤äº† TARGET_STYLES (è·‘æ‰€æœ‰é£æ ¼)
# âŒ ç§»é™¤äº† MAX_IMAGES (è·‘æ‰€æœ‰å›¾ç‰‡)
# =================================================

def scan_saved_counts():
    counts = defaultdict(int)
    if not os.path.isdir(SAVE_ROOT):
        return counts
    for entry in os.listdir(SAVE_ROOT):
        path = os.path.join(SAVE_ROOT, entry)
        if os.path.isdir(path):
            counts[entry] = sum(1 for name in os.listdir(path) if name.endswith(".pt"))
    return counts

def scan_saved_counts_and_max_idx():
    counts = defaultdict(int)
    max_idx = -1
    if not os.path.isdir(SAVE_ROOT):
        return counts, max_idx
    for entry in os.listdir(SAVE_ROOT):
        path = os.path.join(SAVE_ROOT, entry)
        if os.path.isdir(path):
            pt_files = [f for f in os.listdir(path) if f.endswith(".pt")]
            counts[entry] = len(pt_files)
            # æå–æ‰€æœ‰ç¼–å·
            indices = []
            for fname in pt_files:
                try:
                    idx = int(os.path.splitext(fname)[0])
                    indices.append(idx)
                except Exception:
                    continue
            if indices:
                max_idx = max(max_idx, max(indices))
    return counts, max_idx

def load_progress():
    # ä¸å†ä»æ–‡ä»¶è¯»å–è¿›åº¦ï¼Œåªç”¨ç£ç›˜æ‰«æ
    return scan_saved_counts_and_max_idx()

def save_progress(last_idx, counters):
    # ä»…ç”¨äºæ˜¾ç¤ºï¼Œä¸å½±å“æ–­ç‚¹ç»­ä¼ é€»è¾‘
    os.makedirs(os.path.dirname(PROGRESS_FILE), exist_ok=True)
    with open(PROGRESS_FILE, "w", encoding="utf-8") as fp:
        json.dump({"last_idx": last_idx, "counters": counters}, fp, indent=2)

def scan_existing_indices():
    """Return a set of all image indices already encoded (from all style dirs)."""
    existing = set()
    if not os.path.isdir(SAVE_ROOT):
        return existing
    for entry in os.listdir(SAVE_ROOT):
        path = os.path.join(SAVE_ROOT, entry)
        if os.path.isdir(path):
            for fname in os.listdir(path):
                if fname.endswith(".pt"):
                    try:
                        idx = int(os.path.splitext(fname)[0])
                        existing.add(idx)
                    except Exception:
                        continue
    return existing

def run_encode_all():
    print(f"ğŸš€ åˆå§‹åŒ– VAE: {VAE_ID} (FP32)...")
    # å¼ºåˆ¶ FP32ï¼Œç¡®ä¿ç²¾åº¦
    vae = AutoencoderKL.from_pretrained(VAE_ID).to(DEVICE).float()
    vae.eval()

    print(f"ğŸ“¥ åŠ è½½ WikiArt å…¨é‡æ•°æ®é›†...")
    # ä¸ä½¿ç”¨ streamingï¼Œæ–¹ä¾¿é€šè¿‡ç´¢å¼•è·³è¿‡
    dataset = load_dataset("huggan/wikiart", split="train")
    
    # å¤„ç†é£æ ¼æ ‡ç­¾æ˜ å°„
    if 'style' in dataset.features:
        int2str = dataset.features['style'].int2str
    else:
        int2str = lambda x: str(x)

    # âš ï¸ ä¿®æ”¹ï¼šå»ºè®®ä¸è¦æ¯æ¬¡éƒ½å¼ºåˆ¶åˆ é™¤ç›®å½•ï¼Œé˜²æ­¢è¯¯åˆ è·‘äº†å‡ ä¸ªå°æ—¶çš„æˆæœ
    # if os.path.exists(SAVE_ROOT): shutil.rmtree(SAVE_ROOT) 
    os.makedirs(SAVE_ROOT, exist_ok=True)

    # æ–­ç‚¹ç»­ä¼ ï¼šæ‰¾åˆ°å·²å¤„ç†çš„æœ€å¤§ç´¢å¼•
    existing_indices = scan_existing_indices()
    start_idx = max(existing_indices) + 1 if existing_indices else 0
    print(f"â± å·²å­˜åœ¨ {len(existing_indices)} å¼ å›¾ç‰‡ï¼Œä»ç´¢å¼• {start_idx} å¼€å§‹å¤„ç†ã€‚")
    print(f"âš¡ å¼€å§‹å…¨é‡ç¼–ç  (512x512), å…± {len(dataset)} å¼ å›¾ç‰‡...")

    counters = defaultdict(int)
    processed_idx = -1
    with torch.no_grad():
        # ç›´æ¥ä» start_idx å¼€å§‹éå†
        for i in tqdm(range(start_idx, len(dataset)), desc="Encoding"):
            try:
                item = dataset[i]
                # 1. è·å–é£æ ¼åç§°
                style_idx = item['style']
                raw_style = int2str(style_idx)
                style = raw_style.replace(" ", "_").replace("/", "_")
                
                if style not in counters:
                    counters[style] = 0

                # 2. ä¿å­˜è·¯å¾„
                save_dir = os.path.join(SAVE_ROOT, style)
                save_path = os.path.join(save_dir, f"{i}.pt")
                
                # 3. å›¾ç‰‡é¢„å¤„ç†
                img = item['image'].convert("RGB").resize((IMG_SIZE, IMG_SIZE), Image.LANCZOS)
                arr = np.array(img).astype(np.float32) / 127.5 - 1.0
                tensor = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0).to(DEVICE)
                
                # 4. ç¼–ç  + ç¼©æ”¾
                latents = vae.encode(tensor).latent_dist.mode() * SCALING_FACTOR
                
                # 5. ä¿å­˜
                os.makedirs(save_dir, exist_ok=True)
                torch.save(latents.cpu(), save_path)
                
                counters[style] += 1
                processed_idx = i
                if counters[style] % 500 == 0:
                    save_progress(processed_idx, counters)
            except Exception as e:
                print(f"\nâš ï¸ å›¾ç‰‡ {i} å¤„ç†å¤±è´¥: {e}")
                continue
                    
    save_progress(processed_idx, counters)
    print("\nâœ… å…¨é‡ç¼–ç å®Œæˆï¼")
    print("ğŸ“Š æœ€æ–°é£æ ¼ç»Ÿè®¡:")
    for s, c in sorted(counters.items()):
        print(f"  - {s}: {c} å¼ ")

def encode_images_in_dir(img_dir, vae_id=VAE_ID, device=DEVICE, scaling_factor=SCALING_FACTOR, img_size=IMG_SIZE):
    """
    ç¼–ç æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡ï¼Œä¿å­˜ä¸º {img_dir}/latents/{ç›¸å¯¹å­ç›®å½•ç»“æ„}/{åŸæ–‡ä»¶å}.pt
    """
    vae = AutoencoderKL.from_pretrained(vae_id).to(device).float()
    vae.eval()
    img_dir = os.path.abspath(img_dir)
    save_root = os.path.join(img_dir, "latents")
    os.makedirs(save_root, exist_ok=True)

    # æ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼ï¼Œé€’å½’æŸ¥æ‰¾æ‰€æœ‰å­ç›®å½•
    img_files = []
    for ext in ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.webp"]:
        img_files.extend(glob(os.path.join(img_dir, "**", ext), recursive=True))
    img_files = sorted(img_files)
    if not img_files:
        print(f"âŒ No images found in {img_dir}")
        return

    print(f"ğŸš€ Encoding {len(img_files)} images from {img_dir} (with subdirs) ...")
    with torch.no_grad():
        for img_path in tqdm(img_files, desc="Encoding images"):
            try:
                img = Image.open(img_path).convert("RGB").resize((img_size, img_size), Image.LANCZOS)
                arr = np.array(img).astype(np.float32) / 127.5 - 1.0
                tensor = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0).to(device)
                latents = vae.encode(tensor).latent_dist.mode() * scaling_factor
                # ä¿ç•™ç›¸å¯¹å­ç›®å½•ç»“æ„
                rel_path = os.path.relpath(img_path, img_dir)
                rel_dir = os.path.dirname(rel_path)
                base = os.path.splitext(os.path.basename(img_path))[0]
                save_dir = os.path.join(save_root, rel_dir)
                os.makedirs(save_dir, exist_ok=True)
                save_path = os.path.join(save_dir, f"{base}.pt")
                torch.save(latents.cpu(), save_path)
            except Exception as e:
                print(f"âš ï¸ Failed to encode {img_path}: {e}")
    print(f"âœ… All images encoded and saved to {save_root}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--img_dir", type=str, default=None, help="è¦ç¼–ç çš„å›¾ç‰‡ç›®å½•ï¼ˆå¯é€‰ï¼‰")
    args = parser.parse_args()

    if args.img_dir:
        encode_images_in_dir(args.img_dir)
    else:
        run_encode_all()