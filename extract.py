import torch
import torch.nn.functional as F
import os
import glob
import numpy as np
from tqdm import tqdm
import gc

# ================= âš™ï¸ é…ç½®åŒº =================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DATA_ROOT = r"G:\GitHub\VAE_ca_proj\wikiart_latents"
SAVE_DIR = "./output/svd_bases"
TARGET_STYLES = ["Impressionism", "Ukiyo_e", "Cubism", "Art_Nouveau"]

# ç‰©ç†å‚æ•°
PATCH_SIZE = 32
LATENT_DIM = 4  
VECTOR_DIM = LATENT_DIM * PATCH_SIZE * PATCH_SIZE # 4 * 32 * 32 = 4096
NUM_COMPONENTS = 4096 # ä¿ç•™çš„ä¸»æˆåˆ†æ•°é‡ (ä¸è¶…è¿‡ 4096)

# æ­¥é•¿ï¼šå†³å®šé‡‡æ ·å¯†åº¦ã€‚
# 32çš„Patchï¼Œè®¾ä¸º8è¡¨ç¤ºæœ‰75%çš„é‡å ï¼Œä¿è¯æ•°æ®åˆ©ç”¨ç‡æé«˜ã€‚
# å¦‚æœè®¾ä¸º32åˆ™æ˜¯ä¸é‡å é‡‡æ ·ã€‚å»ºè®® 4-16ã€‚
STRIDE = 8 

# æ˜¾å­˜æ§åˆ¶ï¼šæ”’å¤Ÿå¤šå°‘ä¸ª Patch è¿›è¡Œä¸€æ¬¡ GPU è®¡ç®—
# 10000 * 4096 * 4bytes â‰ˆ 160MB æ˜¾å­˜ï¼Œéå¸¸å®‰å…¨
GPU_BATCH_SIZE = 80000 
# ============================================

class TorchIncrementalPCA:
    """
    çº¯ PyTorch å®ç°çš„ GPU å¢é‡ PCA
    æ”¯æŒæ— é™æ•°æ®æµï¼Œæ˜¾å­˜å ç”¨æ’å®š
    """
    def __init__(self, n_components, device="cuda"):
        self.n_components = n_components
        self.device = device
        # åæ–¹å·®çŸ©é˜µç´¯ç§¯å™¨ (X^T @ X) [D, D]
        self.cov_sum = None 
        # å‡å€¼ç´¯ç§¯å™¨ (sum(X)) [D]
        self.mean_sum = None
        # æ ·æœ¬è®¡æ•°
        self.n_samples = 0
        
    def partial_fit(self, batch_data):
        """
        batch_data: [N, D] tensor on GPU
        """
        N, D = batch_data.shape
        
        # åˆå§‹åŒ–ç´¯ç§¯å™¨ (æ‡’åŠ è½½ï¼Œç¡®å®šç»´åº¦)
        if self.cov_sum is None:
            self.cov_sum = torch.zeros((D, D), device=self.device, dtype=torch.float32)
            self.mean_sum = torch.zeros((D,), device=self.device, dtype=torch.float32)
        
        # 1. ç´¯ç§¯å’Œ (ç”¨äºè®¡ç®—å…¨å±€å‡å€¼)
        self.mean_sum += batch_data.sum(dim=0)
        
        # 2. ç´¯ç§¯å¤–ç§¯ (X^T X)
        # è¿™ä¸€æ­¥æ˜¯è®¡ç®—ç“¶é¢ˆï¼ŒGPU åŠ é€Ÿæ•ˆæœæœ€æ˜æ˜¾
        self.cov_sum += torch.matmul(batch_data.T, batch_data)
        
        self.n_samples += N

    def finalize(self):
        """ å¤„ç†å®Œæ‰€æœ‰æ•°æ®åï¼Œæ‰§è¡Œæœ€ç»ˆåˆ†è§£ """
        if self.n_samples < 2: return None

        print(f"   âš™ï¸ æ­£åœ¨æ‰§è¡Œç‰¹å¾åˆ†è§£ (Cov Matrix Size: {self.cov_sum.shape})...")
        
        # 1. è®¡ç®—å…¨å±€å‡å€¼
        mean = self.mean_sum / self.n_samples
        
        # 2. æ„é€ ä¸­å¿ƒåŒ–åæ–¹å·®çŸ©é˜µ
        # å…¬å¼æ¨å¯¼: Cov = (E[XX^T] - E[X]E[X]^T) * N / (N-1)
        # sum((x-u)(x-u)^T) = sum(xx^T) - N*u*u^T
        cov_matrix = self.cov_sum - self.n_samples * torch.outer(mean, mean)
        cov_matrix = cov_matrix / (self.n_samples - 1)
        
        # 3. ç‰¹å¾åˆ†è§£ (Symeig) - æ•°å€¼ç¨³å®šä¸”å¿«
        # eigh é€‚ç”¨äºå¯¹ç§°çŸ©é˜µ
        S, U = torch.linalg.eigh(cov_matrix)
        
        # 4. æ’åº (eigh è¿”å›çš„æ˜¯å‡åºï¼Œæˆ‘ä»¬è¦é™åº)
        S = S.flip(0) # ç‰¹å¾å€¼
        U = U.flip(1) # ç‰¹å¾å‘é‡
        
        # 5. æˆªæ–­
        components = U[:, :self.n_components]
        explained_variance = S[:self.n_components]
        
        ratio = explained_variance.sum() / S.sum()
        
        return {
            "basis": components, # [4096, K]
            "mean": mean,        # [4096]
            "singular_values": torch.sqrt(explained_variance * (self.n_samples - 1)),
            "ratio": ratio
        }

def extract_svd_basis(style_name):
    print(f"\nğŸ“ [å…¨é‡æ¨¡å¼] æ­£åœ¨å¤„ç†é£æ ¼æµå½¢: {style_name}")
    style_dir = os.path.join(DATA_ROOT, style_name)
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    files = glob.glob(os.path.join(style_dir, "*.pt"))
    if not files:
        print(f"âŒ æ— æ•°æ®: {style_dir}")
        return None
    
    print(f"   ğŸ“‚ å‘ç°æ–‡ä»¶: {len(files)} ä¸ª")

    # åˆå§‹åŒ–å¢é‡è®¡ç®—å™¨
    pca = TorchIncrementalPCA(n_components=NUM_COMPONENTS, device=DEVICE)
    
    # ç¼“å†²åŒº
    buffer_list = []
    buffer_count = 0
    
    # è¿›åº¦æ¡
    pbar = tqdm(files, desc="Streaming Patches", unit="file")
    
    for f_path in pbar:
        try:
            # 1. åŠ è½½ Latent
            z = torch.load(f_path, map_location="cpu").float() # [4, 64, 64]
            if z.dim() == 3: z = z.unsqueeze(0)
            
            # 2. Unfold åˆ‡ç‰‡ (å…¨è¦†ç›–ï¼Œæ— éšæœºé‡‡æ ·)
            # ä½¿ç”¨ unfold æå–æ‰€æœ‰å¯èƒ½çš„ Patch
            patches = F.unfold(z, kernel_size=PATCH_SIZE, padding=0, stride=STRIDE)
            # [1, 4096, N_patches] -> [N_patches, 4096]
            patches = patches.permute(0, 2, 1).reshape(-1, VECTOR_DIM)
            
            # åŠ å…¥ç¼“å†²åŒº
            buffer_list.append(patches)
            buffer_count += patches.shape[0]
            
            # 3. ç¼“å†²åŒºæ»¡äº†ï¼Ÿé€å…¥ GPU è®¡ç®—
            if buffer_count >= GPU_BATCH_SIZE:
                # æ‹¼æ¥
                X_batch = torch.cat(buffer_list, dim=0).to(DEVICE)
                
                # å¢é‡æ‹Ÿåˆ
                pca.partial_fit(X_batch)
                
                # æ¸…ç†
                buffer_list = []
                buffer_count = 0
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                pbar.set_postfix({"Total Patches": pca.n_samples})

        except Exception as e:
            # print(f"Error reading {f_path}: {e}")
            continue

    # 4. å¤„ç†å‰©ä½™çš„ç¼“å†²åŒºæ•°æ®
    if buffer_list:
        X_batch = torch.cat(buffer_list, dim=0).to(DEVICE)
        pca.partial_fit(X_batch)
        del X_batch

    if pca.n_samples == 0:
        print("âŒ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆ Patch")
        return None

    print(f"   ğŸ§® æ•°æ®æµç»“æŸã€‚æ€»å¤„ç† Patch æ•°: {pca.n_samples}")
    print(f"   âš™ï¸ æ­£åœ¨è®¡ç®—æœ€ç»ˆ SVD...")
    
    result = pca.finalize()
    
    print(f"   âœ… å®Œæˆã€‚å‰ {NUM_COMPONENTS} ä¸ªåŸºå…ƒè§£é‡Šäº† {result['ratio']:.2%} çš„æ–¹å·®ã€‚")

    return {
        "basis": result["basis"].cpu(),
        "mean": result["mean"].cpu(),
        "singular_values": result["singular_values"].cpu()
    }

if __name__ == "__main__":
    os.makedirs(SAVE_DIR, exist_ok=True)
    
    # æ£€æŸ¥ç»´åº¦
    if NUM_COMPONENTS > VECTOR_DIM:
        print(f"âš ï¸ è¯·æ±‚çš„ä¸»æˆåˆ†æ•° ({NUM_COMPONENTS}) å¤§äºç‰¹å¾ç»´åº¦ ({VECTOR_DIM})ï¼Œå·²ä¿®æ­£ã€‚")
        NUM_COMPONENTS = VECTOR_DIM

    for style in TARGET_STYLES:
        with torch.no_grad():
            data = extract_svd_basis(style)
            if data:
                save_path = os.path.join(SAVE_DIR, f"{style}.pt")
                torch.save(data, save_path)
                print(f"   ğŸ’¾ åŸºå…ƒå·²ä¿å­˜è‡³: {save_path}")