import torch
import os
import json
import numpy as np
import gc
from tqdm import tqdm
from diffusers import AutoencoderKL
from datasets import load_dataset
from torch.utils.data import Dataset, DataLoader
from PIL import Image

# ================= ğŸš€ åŠ é€Ÿé…ç½®åŒº =================
# åœ¨ FP32 + Tiling æ¨¡å¼ä¸‹ï¼š
# 12G æ˜¾å­˜è¯• 1-2
# 16G æ˜¾å­˜è¯• 2-4
# 24G æ˜¾å­˜è¯• 4-8
BATCH_SIZE = 1 

NUM_WORKERS = 32
VAE_ID = "stabilityai/sdxl-vae"
IMG_SIZE = 1024
SCALING_FACTOR = 0.13025
SAVE_ROOT = "./wikiart_latents"
PROGRESS_FILE = os.path.join(SAVE_ROOT, "progress.json")
DATASET_ID = "huggan/wikiart"
DEVICE = "cuda"
# ã€æ–°å¢ã€‘æ”¯æŒä»æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹ï¼ˆè‹¥å­˜åœ¨ï¼‰
CACHE_DIR = os.getenv("HF_CACHE_DIR") or os.getenv("HF_HOME") or os.path.join(os.path.expanduser("~"), ".cache", "huggingface")
# ===============================================

class WikiArtDataset(Dataset):
    def __init__(self, hf_dataset, img_size):
        self.data = hf_dataset
        self.img_size = img_size
        if 'style' in hf_dataset.features:
            self.int2str = hf_dataset.features['style'].int2str
        else:
            self.int2str = lambda x: str(x)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        image = item['image']
        if not image.mode == "RGB":
            image = image.convert("RGB")
        image = image.resize((self.img_size, self.img_size), resample=Image.LANCZOS)
        img_arr = np.array(image).astype(np.float32) / 127.5 - 1.0
        img_tensor = torch.from_numpy(img_arr).permute(2, 0, 1)
        style_idx = item['style']
        style_name = self.int2str(style_idx)
        safe_style_name = style_name.replace(" ", "_").replace("/", "_")
        filename = f"img_{idx:06d}.pt"
        return {
            "pixel_values": img_tensor,
            "style_dir": safe_style_name,
            "filename": filename,
            "idx": idx
        }

def load_progress():
    """åŠ è½½è¿›åº¦æ–‡ä»¶ï¼Œè¿”å›å·²å¤„ç†çš„ (style_dir, filename) é›†åˆ"""
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r') as f:
            data = json.load(f)
            processed = set()
            for item in data.get('processed', []):
                processed.add((item['style_dir'], item['filename']))
            return processed, data.get('last_idx', -1)
    return set(), -1

def save_progress(processed_set, last_idx):
    """ä¿å­˜è¿›åº¦åˆ°æ–‡ä»¶"""
    data = {
        'processed': [
            {'style_dir': sd, 'filename': fn} 
            for sd, fn in sorted(processed_set)
        ],
        'last_idx': last_idx
    }
    os.makedirs(os.path.dirname(PROGRESS_FILE), exist_ok=True)
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(data, f, indent=2)

def _load_vae_from_cache_or_online(model_id, cache_dir=None, torch_dtype=torch.float32):
    """Try loading from local cache first (local_files_only=True). On failure, fall back to online."""
    if cache_dir and os.path.exists(cache_dir):
        try:
            print(f"ğŸ” å°è¯•ä»ç¼“å­˜åŠ è½½ {model_id} (cache_dir={cache_dir}) ...")
            return AutoencoderKL.from_pretrained(model_id, cache_dir=cache_dir, local_files_only=True, torch_dtype=torch_dtype)
        except Exception as e:
            print(f"âš ï¸ æœ¬åœ°åŠ è½½å¤±è´¥: {e}ï¼Œå°†å›é€€åˆ°åœ¨çº¿ä¸‹è½½ã€‚")
    print(f"ğŸŒ ä»åœ¨çº¿ä¸‹è½½ {model_id} ...")
    return AutoencoderKL.from_pretrained(model_id, torch_dtype=torch_dtype)

def run_fast_encoding():
    # 1. åˆå§‹åŒ– VAE (ä¸¥æ ¼ä¿æŒ FP32)
    print(f"ğŸš€ åŠ è½½ VAE: {VAE_ID} (FP32)...")
    vae = _load_vae_from_cache_or_online(VAE_ID, cache_dir=CACHE_DIR, torch_dtype=torch.float32).to(DEVICE)
    
    # ã€å…³é”®ä¿®æ”¹ç‚¹ 1ã€‘å¼€å¯ Tiling (åˆ‡å—)
    # è¿™ä¸€æ­¥ä¸åŠ¨æ•°æ®ç²¾åº¦ï¼Œè€Œæ˜¯å°†å¤§å›¾åˆ‡æˆå°å—åˆ†åˆ«è¿›æ˜¾å¡è®¡ç®—ï¼Œæœ€åæ‹¼åˆã€‚
    # å®ƒæ˜¯ä»¥"è®¡ç®—æ—¶é—´"æ¢"æ˜¾å­˜ç©ºé—´"çš„å”¯ä¸€ FP32 æ•‘å‘½ç¨»è‰ã€‚
    vae.enable_tiling()
    
    # ã€å…³é”®ä¿®æ”¹ç‚¹ 2ã€‘å¼€å¯ xFormers (å¦‚æœç¯å¢ƒæ”¯æŒ)
    # è¿™ä¼šä¼˜åŒ– Attention çš„æ˜¾å­˜å ç”¨ï¼Œä¸”åœ¨ FP32 ä¸‹ç²¾åº¦æ— æŸã€‚
    # å¦‚æœæŠ¥é”™ï¼Œè¯·æ³¨é‡Šæ‰è¿™ä¸€è¡Œã€‚
    try:
        vae.enable_xformers_memory_efficient_attention()
        print("ğŸ§  xFormers memory-efficient attention å·²å¯ç”¨")
    except Exception as exc:
        print(f"âš ï¸ æ— æ³•å¯ç”¨ xFormers: {exc}")

    vae.eval()
    vae.requires_grad_(False)

    # ã€æ–°å¢ã€‘åŠ è½½è¿›åº¦
    processed_set, last_idx = load_progress()
    print(f"ğŸ“Š å·²å¤„ç† {len(processed_set)} å¼ å›¾ç‰‡ï¼Œä¸Šæ¬¡ä¸­æ–­åœ¨ idx={last_idx}")

    print(f"ğŸ“¥ åŠ è½½æ•°æ®é›†...")
    hf_dataset = load_dataset(DATASET_ID, split="train")
    torch_dataset = WikiArtDataset(hf_dataset, IMG_SIZE)
    
    loader = DataLoader(
        torch_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS,
        pin_memory=True,     
        drop_last=False
    )

    print(f"âš¡ å¼€å§‹ FP32 ç¼–ç  (Tiling å¼€å¯ï¼Œæ–­ç‚¹ç»­è·‘å·²å¯ç”¨)")
    
    os.makedirs(SAVE_ROOT, exist_ok=True)
    
    current_last_idx = last_idx
    
    with torch.no_grad():
        for batch in tqdm(loader, desc="Encoding"):
            # ä¿æŒ FP32
            imgs = batch["pixel_values"].to(DEVICE, dtype=torch.float32)
            
            # ç¼–ç 
            latents = vae.encode(imgs).latent_dist.mode()
            latents = latents * SCALING_FACTOR
            
            # æ¬å› CPU
            latents = latents.cpu()
            
            # ã€å…³é”®ä¿®æ”¹ç‚¹ 3ã€‘æ‰‹åŠ¨æ¸…ç†æ˜¾å­˜å¼•ç”¨
            # åœ¨ Python ä¸­ï¼Œè™½ç„¶å˜é‡å‡ºäº†ä½œç”¨åŸŸä¼šé”€æ¯ï¼Œä½†æ˜¾å­˜é‡Šæ”¾æœ‰æ—¶æœ‰æ»åã€‚
            # æ‰‹åŠ¨åˆ é™¤ GPU ä¸Šçš„å˜é‡å¼•ç”¨ï¼Œæœ‰åŠ©äºç¼“è§£æ˜¾å­˜ç¢ç‰‡åŒ–ã€‚
            del imgs

            for i in range(latents.shape[0]):
                style_dir = batch["style_dir"][i]
                fname = batch["filename"][i]
                current_idx = batch["idx"][i].item()
                
                # ã€æ–°å¢ã€‘æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                if (style_dir, fname) in processed_set:
                    continue
                
                latent_tensor = latents[i]
                
                full_dir = os.path.join(SAVE_ROOT, style_dir)
                os.makedirs(full_dir, exist_ok=True)
                
                save_path = os.path.join(full_dir, fname)
                if not os.path.exists(save_path):
                    torch.save(latent_tensor, save_path)
                
                # ã€æ–°å¢ã€‘æ›´æ–°è¿›åº¦
                processed_set.add((style_dir, fname))
                current_last_idx = current_idx
                
                # æ¯å¤„ç† 100 å¼ å›¾å°±ä¿å­˜ä¸€æ¬¡è¿›åº¦ï¼ˆé˜²æ­¢å…¨éƒ¨ä¸¢å¤±ï¼‰
                if len(processed_set) % 100 == 0:
                    save_progress(processed_set, current_last_idx)

    # ã€æ–°å¢ã€‘æœ€åä¿å­˜ä¸€æ¬¡è¿›åº¦
    save_progress(processed_set, current_last_idx)
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {len(processed_set)} å¼ å›¾ç‰‡")
    print(f"ğŸ“ è¿›åº¦å·²ä¿å­˜è‡³ {PROGRESS_FILE}")

if __name__ == "__main__":
    torch.multiprocessing.set_start_method('spawn', force=True)
    run_fast_encoding()