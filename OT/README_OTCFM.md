# OT-CFM é£æ ¼è¿ç§»ç³»ç»Ÿ

åŸºäº**æœ€ä¼˜ä¼ è¾“æ¡ä»¶æµåŒ¹é… (Optimal Transport Conditional Flow Matching)** å’Œ**ç­‰è·æµå½¢æ˜ å°„ (Isotropic Manifold Mapping)** çš„é«˜æ•ˆé£æ ¼è¿ç§»ç³»ç»Ÿã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- âœ… **çº¯æ•°å­¦é©±åŠ¨**: åŸºäº ODE å¯é€†æ€§ï¼Œæ— éœ€å¯¹æŠ—è®­ç»ƒ
- âœ… **è½»é‡é«˜æ•ˆ**: ä¸“ä¸º 8GB VRAM ä¼˜åŒ–ï¼Œæ”¯æŒ RTX 4070 Laptop
- âœ… **ç»“æ„å®ˆæ’**: Inversion + Generation åŒå‘æµç¨‹ä¿è¯ç»“æ„ä¸€è‡´æ€§
- âœ… **å¿«é€Ÿæ¨ç†**: 10-20 æ­¥ ODE æ±‚è§£å³å¯å®Œæˆé£æ ¼è¿ç§»
- âœ… **åº•å±‚ä¼˜åŒ–**: torch.compile + BF16 + TF32 + channels_last

## ğŸ“¦ æ–‡ä»¶ç»“æ„

```
.
â”œâ”€â”€ model.py                    # æ¨¡å‹æ¶æ„ (IsoNext, AdaGN, TimestepEmb)
â”œâ”€â”€ train.py                    # è®­ç»ƒè„šæœ¬ (OT-CFM Loss)
â”œâ”€â”€ inference.py                # æ¨ç†è„šæœ¬ (Inversion + Generation)
â”œâ”€â”€ preprocess_latents.py       # æ•°æ®é¢„å¤„ç† (VAE Encoding)
â”œâ”€â”€ test_model.py               # æ¨¡å‹æµ‹è¯•è„šæœ¬
â”œâ”€â”€ config.json                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ USAGE_GUIDE.md             # è¯¦ç»†ä½¿ç”¨æŒ‡å—
â””â”€â”€ README.md                   # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install diffusers transformers accelerate pillow numpy tqdm
```

### 2. æµ‹è¯•æ¨¡å‹

```bash
python test_model.py
```

è¿™å°†éªŒè¯ï¼š
- æ¨¡å‹æ¶æ„æ­£ç¡®æ€§
- OT-CFM æŸå¤±è®¡ç®—
- æ˜¾å­˜å ç”¨æƒ…å†µ
- channels_last åŠ é€Ÿæ•ˆæœ

### 3. å‡†å¤‡æ•°æ®

å°†æ•°æ®ç»„ç»‡ä¸ºï¼š
```
raw_data/
â”œâ”€â”€ style_0/
â”‚   â””â”€â”€ *.jpg
â””â”€â”€ style_1/
    â””â”€â”€ *.jpg
```

ç„¶åè¿è¡Œé¢„å¤„ç†ï¼š
```bash
python preprocess_latents.py --config config.json
```

### 4. è®­ç»ƒ

```bash
python train.py
```

æ¨¡å‹å°†ä¿å­˜åœ¨ `checkpoints/` ç›®å½•ã€‚

### 5. æ¨ç†

```bash
python inference.py \
  --checkpoint checkpoints/stage1_epoch200.pt \
  --input test.jpg \
  --source_style 0 \
  --target_style 1 \
  --output result.png \
  --num_steps 20
```

## ğŸ“ æ•°å­¦åŸç†

### OT-CFM æµåŒ¹é…

å°†é£æ ¼è¿ç§»å»ºæ¨¡ä¸ºåœ¨æ¦‚ç‡æµå½¢ä¸Šå¯»æ‰¾æœ€ä¼˜è·¯å¾„ï¼š

$$p_t(x) = (1-t) \cdot \mathcal{N}(0, I) + t \cdot p_{\text{data}}(x)$$

ç›®æ ‡ï¼šå­¦ä¹ é€Ÿåº¦åœº $v_\theta(x_t, t, c)$ ä½¿å¾—ï¼š

$$\frac{dx}{dt} = v_\theta(x_t, t, c)$$

æŸå¤±å‡½æ•°æå…¶ç®€æ´ï¼š

$$\mathcal{L} = \mathbb{E}_{x_0, x_1, t} \left[ \| v_\theta(x_t, t, c) - (x_1 - x_0) \|^2 \right]$$

### ç»“æ„å®ˆæ’å›è·¯

åˆ©ç”¨ ODE å¯é€†æ€§å®ç°ç»“æ„å®ˆæ’ï¼š

1. **Inversion (ç»“æ„æå‡º)**
   ```
   xâ‚ --[åå‘ODE]--> xâ‚€
   (æºå›¾ç‰‡)           (ç»“æ„åæ ‡)
   ```

2. **Generation (é£æ ¼é‡ç»˜)**
   ```
   xâ‚€ --[æ­£å‘ODE]--> xâ‚'
   (ç»“æ„åæ ‡)         (ç›®æ ‡é£æ ¼)
   ```

### AdaGN (è‡ªé€‚åº”ç»„å½’ä¸€åŒ–)

æ ¸å¿ƒé£æ ¼æ³¨å…¥æœºåˆ¶ï¼š

```python
x_norm = GroupNorm(x)                    # ä¿ç•™ç»“æ„
scale, shift = MLP(style_embedding)      # é¢„æµ‹ä»¿å°„å‚æ•°
x_styled = scale * x_norm + shift        # æ³¨å…¥é£æ ¼
```

## ğŸ¯ æ¨¡å‹æ¶æ„

```
IsoNext (ç­‰è· ConvNeXt)
â”œâ”€â”€ Input Projection: [4, H, W] -> [D, H, W]
â”œâ”€â”€ Isotropic Blocks (Ã—12-18)
â”‚   â”œâ”€â”€ Depthwise Conv 7Ã—7
â”‚   â”œâ”€â”€ AdaGN (é£æ ¼æ³¨å…¥)
â”‚   â”œâ”€â”€ Pointwise Conv (å‡ç»´)
â”‚   â”œâ”€â”€ GELU
â”‚   â”œâ”€â”€ Pointwise Conv (é™ç»´)
â”‚   â””â”€â”€ Residual Connection
â””â”€â”€ Output Projection: [D, H, W] -> [4, H, W]
```

**å…³é”®ç‰¹æ€§**:
- å…¨ç­‰è·æ¶æ„ï¼Œæ— ä¸‹é‡‡æ ·
- å¤§æ ¸å·ç§¯ (7Ã—7) æ•æ‰å…¨å±€ç»“æ„
- AdaGN å®ç°é£æ ¼æµåŠ¨æ€§
- æ®‹å·®è¿æ¥ä¿è¯æ¢¯åº¦æµåŠ¨

## âš™ï¸ é…ç½®è¯´æ˜

ç¼–è¾‘ `config.json`:

```json
{
  "model": {
    "hidden_dim": 384,        // éšè—å±‚ç»´åº¦ (384/512)
    "num_layers": 12,         // ç½‘ç»œæ·±åº¦ (12-18)
    "num_styles": 2           // é£æ ¼ç±»åˆ«æ•°
  },
  "training": {
    "batch_size": 64,         // æ‰¹é‡å¤§å°
    "learning_rate": 1e-4,
    "stage1_epochs": 200,     // è®­ç»ƒè½®æ•°
    "label_drop_prob": 0.15   // CFG dropping æ¦‚ç‡
  }
}
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

**æ˜¾å­˜å ç”¨** (Batch Size 64, Hidden Dim 384):
- æ¨¡å‹: ~350MB
- è®­ç»ƒå³°å€¼: ~6.5GB
- æ¨ç†å³°å€¼: ~2GB

**è®­ç»ƒé€Ÿåº¦** (RTX 4070):
- ~0.5 sec/batch (BF16 + compile)
- ~2000 batches/epoch
- ~16 min/epoch

**æ¨ç†é€Ÿåº¦**:
- 10 æ­¥ Euler: ~0.3s
- 20 æ­¥ RK4: ~0.8s

## ğŸ”¬ åº•å±‚ä¼˜åŒ–æŠ€æœ¯

1. **é¢„è®¡ç®— Latents**: æ¶ˆé™¤ VAE Encoder ç“¶é¢ˆ
2. **BFloat16 AMP**: å‡å°‘æ˜¾å­˜ ~50%ï¼ŒåŠ é€Ÿ ~2x
3. **torch.compile**: å‡å°‘ Python è§£é‡Šå™¨å¼€é”€
4. **channels_last**: æå‡å·ç§¯ååé‡ ~20%
5. **TF32**: è‡ªåŠ¨å¯ç”¨ Tensor Cores
6. **Gradient Checkpointing**: (å¯é€‰) è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜

## ğŸ¨ ä½¿ç”¨åœºæ™¯

- ç…§ç‰‡ â†’ æ²¹ç”»é£æ ¼
- ç´ æ â†’ å½©è‰²ä½œå“
- ç°å® â†’ å¡é€šé£æ ¼
- ä»»æ„é£æ ¼åŸŸè¿ç§»

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Flow Matching for Generative Modeling**  
   Lipman et al., ICLR 2023

2. **Improving and Generalizing Flow-Based Generative Models with Optimal Transport**  
   Tong et al., TMLR 2023

3. **ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders**  
   Woo et al., CVPR 2023

4. **Classifier-Free Diffusion Guidance**  
   Ho & Salimans, NeurIPS 2021 Workshop

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»

é‡åˆ°é—®é¢˜ï¼Ÿè¯·æŸ¥çœ‹ [USAGE_GUIDE.md](USAGE_GUIDE.md) è·å–è¯¦ç»†è¯´æ˜ã€‚

---

**Built with â¤ï¸ and Mathematics**
