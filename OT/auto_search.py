import sys
import os
import torch
import gc
import time
from pathlib import Path
from train import LSFMTrainer

# ğŸŸ¢ æ–°å¢ï¼šå¯¼å…¥è¯„ä¼°æ¨¡å—
from eval_lpips import Evaluator as LPIPSEvaluator
from eval_clip import Evaluator as CLIPEvaluator
from eval_vgg import Evaluator as VGGEvaluator

# ==============================================================================
# ğŸ›ï¸ å®éªŒé…ç½®ä¸­å¿ƒ
# è¿™é‡Œåˆ—å‡ºçš„æ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒä»»åŠ¡ã€‚
# å­—å…¸ä¸­çš„ç»“æ„ä¸ config.json å®Œå…¨ä¸€è‡´ï¼Œæœªåˆ—å‡ºçš„å‚æ•°å°†ä½¿ç”¨ config.json çš„é»˜è®¤å€¼ã€‚
# ==============================================================================

EXPERIMENTS = [
    
    # -------------------------------------------------------------------------
    # ç¬¬ä¸€ç»„ï¼šåŸºå‡† (Baseline)
    # -------------------------------------------------------------------------
    {
        "name": "Exp1_Baseline",
        "description": "ã€åŸºå‡†çº¿ã€‘å„é¡¹å‚æ•°ä¸­åº¸ï¼Œç”¨äºå¯¹æ¯”å…¶ä»–å®éªŒçš„æå‡å¹…åº¦ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "transfer_loss_weight": 5.0,
            "stage1_epochs": 100,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬äºŒç»„ï¼šæ¿€è¿›é£æ ¼ (Aggressive Style)
    # éªŒè¯ï¼šæ˜¯å¦åªæœ‰åŠ å¤§æƒ©ç½šæƒé‡ï¼Œæ‰èƒ½é€¼å‡ºæ˜æ˜¾çš„ç…§ç‰‡é£æ ¼ï¼Ÿ
    # é£é™©ï¼šç”»é¢å¯èƒ½å‡ºç°é«˜é¢‘å™ªç‚¹æˆ–è‰²å½©æº¢å‡ºã€‚
    # -------------------------------------------------------------------------
    {
        "name": "Exp2_HighForce",
        "description": "ã€é«˜å‹ç­–ç•¥ã€‘20å€æƒé‡ï¼Œå¼ºè¿«æ¨¡å‹å¤§å¹…åº¦ä¿®æ”¹åŸå›¾ã€‚LRç•¥é™é˜²æ­¢è·‘é£ã€‚",
        "training": {
            "learning_rate": 8e-5,
            "transfer_loss_weight": 20.0, 
            "stage1_epochs": 120,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬ä¸‰ç»„ï¼šç²¾ç»†æ‰“ç£¨ (Precision Mode) - é‡ç‚¹å…³æ³¨ï¼
    # éªŒè¯ï¼šä¹‹å‰çš„è¤ªè‰²/æ¨¡ç³Šæ˜¯å¦å› ä¸ºæ­¥å­å¤ªå¤§ï¼Ÿå°æ­¥æ…¢è·‘èƒ½å¦ç”»å‡ºé«˜æ¸…ç»†èŠ‚ï¼Ÿ
    # é¢„æœŸï¼šLPIPS åˆ†æ•°åº”è¯¥æœ€ä½ï¼ˆæœ€å¥½ï¼‰ï¼Œä½†è®­ç»ƒæœ€æ…¢ã€‚
    # -------------------------------------------------------------------------
    {
        "name": "Exp3_SlowCook",
        "description": "ã€æ…¢å·¥ç»†æ´»ã€‘æä½LR + é•¿Epoch + é«˜æƒé‡ã€‚æ—¨åœ¨è§£å†³è¤ªè‰²å’Œæ¨¡ç³Šã€‚",
        "training": {
            "learning_rate": 2e-5,       # åªæœ‰åŸºå‡†çš„ 1/5
            "transfer_loss_weight": 15.0, # æƒé‡è¾ƒé«˜ï¼Œä¿è¯æ–¹å‘
            "stage1_epochs": 300,         # æ—¶é—´æ¢è´¨é‡
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬å››ç»„ï¼šå¿«é€Ÿæ”¶æ•› (Fast Convergence)
    # éªŒè¯ï¼šæ¨¡å‹æ˜¯å¦å…¶å®å‰50è½®å°±å­¦å®Œäº†ï¼Ÿæ˜¯ä¸æ˜¯åé¢éƒ½åœ¨è¿‡æ‹Ÿåˆï¼Ÿ
    # -------------------------------------------------------------------------
    {
        "name": "Exp4_SpeedRun",
        "description": "ã€æé€Ÿç‰ˆã€‘é«˜LR + ä½Epochã€‚æµ‹è¯•æ¨¡å‹çš„å­¦ä¹ ä¸Šé™é€Ÿåº¦ã€‚",
        "training": {
            "learning_rate": 2e-4,       # åŸºå‡†çš„ 2 å€
            "transfer_loss_weight": 8.0,
            "stage1_epochs": 80,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬äº”ç»„ï¼šæç«¯æƒé‡æµ‹è¯• (Stress Test)
    # éªŒè¯ï¼šå¦‚æœç»™ 50 å€æƒé‡ï¼Œæ¨¡å‹æ˜¯ä¼šç”»å‡ºå®Œç¾çš„ç…§ç‰‡ï¼Œè¿˜æ˜¯ä¼šå½»åº•å´©åæˆå™ªå£°ï¼Ÿ
    # ç›®çš„ï¼šå¯»æ‰¾æƒé‡çš„â€œå´©æºƒä¸´ç•Œç‚¹â€ã€‚
    # -------------------------------------------------------------------------
    {
        "name": "Exp5_WeightStress",
        "description": "ã€å‹åŠ›æµ‹è¯•ã€‘50å€æƒé‡ã€‚æ¢ç´¢æ¨¡å‹çš„é²æ£’æ€§è¾¹ç•Œã€‚",
        "training": {
            "learning_rate": 5e-5,
            "transfer_loss_weight": 50.0, # æç«¯çš„æƒ©ç½š
            "stage1_epochs": 100,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬å…­ç»„ï¼šæ¾å¼›æ§åˆ¶ (Relaxed Control)
    # éªŒè¯ï¼šå¦‚æœåªç»™ä¸€ç‚¹ç‚¹å‹åŠ›ï¼Œæ¨¡å‹æ˜¯å¦ä¼šä¿ç•™æ›´å¤šåŸå›¾ç»“æ„ï¼ˆIdentityï¼‰ä½†ç”»è´¨æ›´è‡ªç„¶ï¼Ÿ
    # -------------------------------------------------------------------------
    {
        "name": "Exp6_Gentle",
        "description": "ã€å¾®è°ƒæ¨¡å¼ã€‘ä½æƒé‡ã€‚æµ‹è¯•æ˜¯å¦èƒ½ä»…æ”¹å˜å…‰å½±è€Œä¸ç ´åç»“æ„ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "transfer_loss_weight": 2.0,  # éå¸¸æ¸©å’Œ
            "stage1_epochs": 150,
        }
    },

    # -------------------------------------------------------------------------
    # ç¬¬ä¸ƒç»„ï¼šå¤§ Batch Size (High Stability)
    # éªŒè¯ï¼šæ˜¾å­˜å…è®¸çš„æƒ…å†µä¸‹ï¼Œæ›´å¤§çš„ Batch Size æ˜¯å¦èƒ½å¸¦æ¥æ›´ç¨³å®šçš„æ¢¯åº¦ä¸‹é™ï¼Ÿ
    # æ³¨æ„ï¼š4070 8G è·‘ BS=96 å¯èƒ½ä¼š OOMï¼Œå¦‚æœç‚¸äº†è¯·è·³è¿‡ã€‚
    # -------------------------------------------------------------------------
    {
        "name": "Exp7_HighBS",
        "description": "ã€é«˜ç¨³å®šæ€§ã€‘å¤§Batch Sizeã€‚æ¢¯åº¦ä¼°è®¡æ›´å‡†ï¼Œç†è®ºä¸Šè‰²å½©æ›´æ­£ã€‚",
        "training": {
            "learning_rate": 1e-4,
            "transfer_loss_weight": 10.0,
            "batch_size": 80,             # æŒ‘æˆ˜æ˜¾å­˜æé™
            "stage1_epochs": 120,
        }
    }
]
# ==============================================================================
# ğŸŸ¢ ä¿®æ”¹ï¼šè¯„ä¼°å‡½æ•° - ç»Ÿä¸€è¾“å‡ºåˆ°å®éªŒç›®å½•
# ==============================================================================
def run_evaluations(ckpt_path, exp_name, exp_ckpt_dir, config_path="config.json"):
    """
    è¿è¡Œæ‰€æœ‰ä¸‰ä¸ªè¯„ä¼°è„šæœ¬å¹¶è®°å½•ç»“æœ
    æ‰€æœ‰è¯„ä¼°ç»“æœç»Ÿä¸€ä¿å­˜åˆ° exp_ckpt_dir/evaluation/ ä¸‹
    """
    import json
    
    # ğŸŸ¢ åˆ›å»ºç»Ÿä¸€çš„è¯„ä¼°ç»“æœç›®å½•
    eval_dir = Path(exp_ckpt_dir) / "evaluation"
    eval_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š Running Evaluations for: {exp_name}")
    print(f"ğŸ“‚ Results will be saved to: {eval_dir}")
    print("="*60)
    
    # è¯»å–é…ç½®è·å–å‚è€ƒç›®å½•
    with open(config_path, 'r', encoding='utf-8') as f:
        cfg = json.load(f)
    
    ref_dir = cfg.get("data", {}).get("data_root", None)
    if ref_dir:
        ref_dir = ref_dir.strip('"').strip("'")
    
    target_dir = cfg.get("inference", {}).get("image_path", "").strip('"').strip("'")
    
    # ğŸŸ¢ æ±‡æ€»ç»“æœå­—å…¸
    results_summary = {
        "experiment_name": exp_name,
        "checkpoint_path": str(ckpt_path),
        "evaluation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "metrics": {}
    }
    
    # 1. LPIPS Evaluation
    try:
        print("\nğŸ”¹ [1/3] Running LPIPS Evaluation...")
        if not target_dir:
            raise ValueError("Target directory not configured in config.json")
        lpips_eval = LPIPSEvaluator(str(ckpt_path), config_path)
        lpips_results = lpips_eval.evaluate(target_dir, batch_size=2, save_dir=str(eval_dir))
        results_summary["metrics"]["lpips"] = lpips_results
        del lpips_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… LPIPS Evaluation Complete")
    except Exception as e:
        print(f"âŒ LPIPS Evaluation Failed: {e}")
        results_summary["metrics"]["lpips"] = {"error": str(e)}
    
    # 2. CLIP Evaluation
    try:
        print("\nğŸ”¹ [2/3] Running CLIP Evaluation...")
        if not target_dir:
            raise ValueError("Target directory not configured in config.json")
        clip_eval = CLIPEvaluator(str(ckpt_path), config_path)
        clip_results = clip_eval.evaluate(target_dir, batch_size=2, save_dir=str(eval_dir))
        results_summary["metrics"]["clip"] = clip_results
        del clip_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… CLIP Evaluation Complete")
    except Exception as e:
        print(f"âŒ CLIP Evaluation Failed: {e}")
        results_summary["metrics"]["clip"] = {"error": str(e)}
    
    # 3. VGG Style Evaluation
    try:
        print("\nğŸ”¹ [3/3] Running VGG Style Evaluation...")
        vgg_eval = VGGEvaluator(str(ckpt_path), ref_root=ref_dir, config_path=config_path)
        # ğŸŸ¢ ä¿®æ”¹ï¼šä¼ å…¥ä¿å­˜è·¯å¾„
        vgg_results = vgg_eval.evaluate(bs=1, save_dir=str(eval_dir))
        results_summary["metrics"]["vgg"] = vgg_results
        del vgg_eval
        gc.collect()
        torch.cuda.empty_cache()
        print("âœ… VGG Evaluation Complete")
    except Exception as e:
        print(f"âŒ VGG Evaluation Failed: {e}")
        results_summary["metrics"]["vgg"] = {"error": str(e)}
    
    # ğŸŸ¢ ä¿å­˜æ±‡æ€»ç»“æœåˆ° JSON
    summary_path = eval_dir / "metrics_summary.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=4, ensure_ascii=False)
    
    print("\n" + "="*60)
    print(f"ğŸ“Š All Evaluations Finished for: {exp_name}")
    print(f"ğŸ“„ Summary saved to: {summary_path}")
    print("="*60)
    
    return results_summary

# ==============================================================================
# è‡ªåŠ¨åŒ–å¼•æ“ (Auto-Pilot)
# ==============================================================================
def run_grid_search():
    # ç»“æœæ€»æ ¹ç›®å½•
    ROOT_SAVE_DIR = Path("AutoSearch_Results")
    ROOT_SAVE_DIR.mkdir(exist_ok=True)
    
    print(f"ğŸš€ Starting Grid Search: {len(EXPERIMENTS)} Experiments Queued.")
    print(f"ğŸ“‚ Root Output: {ROOT_SAVE_DIR.absolute()}")

    for i, exp in enumerate(EXPERIMENTS):
        exp_name = exp['name']
        print("\n" + "#"*60)
        print(f"â–¶ï¸  [{i+1}/{len(EXPERIMENTS)}] Running Experiment: {exp_name}")
        print(f"â„¹ï¸  Description: {exp.get('description', 'N/A')}")
        print("#"*60)

        # 1. æ„é€ æœ¬æ¬¡å®éªŒçš„ä¸“å±ç›®å½•
        exp_dir = ROOT_SAVE_DIR / exp_name
        ckpt_dir = exp_dir / "checkpoints"
        vis_dir = exp_dir / "visualizations"
        
        # ğŸŸ¢ æ–°å¢ï¼šå¦‚æœå‘ç°æ—§æ ¼å¼ checkpointï¼Œæ¸…ç†æ‰é˜²æ­¢å†²çª
        if ckpt_dir.exists():
            old_ckpts = list(ckpt_dir.glob("stage1_epoch*.pt"))
            if old_ckpts:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ˜¯å¦ä¸ºæ—§æ ¼å¼
                try:
                    test_ckpt = torch.load(old_ckpts[0], map_location='cpu')
                    if 'model_state_dict' not in test_ckpt:
                        print(f"âš ï¸  Found old format checkpoints in {ckpt_dir.name}")
                        print(f"ğŸ—‘ï¸  Cleaning up {len(old_ckpts)} old checkpoints...")
                        for old in old_ckpts:
                            old.unlink()
                        print("âœ… Cleanup complete")
                except:
                    pass
        
        # 2. æ„é€ é…ç½®è¦†ç›– (Override)
        config_override = {
            "checkpoint": {
                "save_dir": str(ckpt_dir)
            },
            "inference": {
                "save_dir": str(vis_dir),
                "num_inference_steps": 4 
            }
        }
        
        # å°†ç”¨æˆ·å®šä¹‰çš„å‚æ•°åˆå¹¶è¿›å» (training, model, data ç­‰)
        for k, v in exp.items():
            if k not in ["name", "description"]:
                config_override[k] = v

        start_time = time.time()
        trainer = None

        try:
            # 3. å®ä¾‹åŒ–è®­ç»ƒå™¨ (ä¼ å…¥è¦†ç›–å‚æ•°)
            trainer = LSFMTrainer(config_override=config_override)
            
            # 4. è¿è¡Œè®­ç»ƒ (åªè·‘ Stage 1 å³å¯å¿«é€ŸéªŒè¯é£æ ¼)
            trainer.run_stage1()
            
            # 5. ğŸŸ¢ ä¿®å¤ï¼šå¼ºåˆ¶æ‰§è¡Œä¸€æ¬¡æœ€ç»ˆæ¨ç†
            print("ğŸ¨ Running Final Inference...")
            final_ckpt = trainer.ckpt_dir / "stage1_final.pt"
            if final_ckpt.exists():
                final_model = trainer.get_model()
                
                # ğŸŸ¢ æ­£ç¡®åŠ è½½ï¼šå…ˆè¯»å–checkpointï¼Œæå–model_state_dict
                ckpt_data = torch.load(final_ckpt, map_location=trainer.device)
                if 'model_state_dict' in ckpt_data:
                    trainer.safe_load(final_model, ckpt_data['model_state_dict'])
                else:
                    trainer.safe_load(final_model, ckpt_data)
                
                trainer.do_inference(final_model, "final", "stage1_final")
                
                # æ¸…ç†
                del final_model
                gc.collect()
                torch.cuda.empty_cache()
            
            print(f"âœ… Experiment [{exp_name}] Training Completed in {(time.time() - start_time)/60:.1f} mins.")
            
            # ğŸŸ¢ 6. è¿è¡Œè¯„ä¼°è„šæœ¬ - ä¼ å…¥ ckpt_dir
            if final_ckpt.exists():
                # å…ˆæ¸…ç†è®­ç»ƒå™¨é‡Šæ”¾æ˜¾å­˜
                del trainer
                gc.collect()
                torch.cuda.empty_cache()
                trainer = None  # æ ‡è®°å·²åˆ é™¤
                
                run_evaluations(final_ckpt, exp_name, ckpt_dir)

        except KeyboardInterrupt:
            print("\nğŸ›‘ User Interrupted. Exiting...")
            sys.exit(0)
        except Exception as e:
            print(f"\nâŒ Experiment [{exp_name}] Failed!")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # 7. æ˜¾å­˜æ¸…ç† (è‡³å…³é‡è¦)
            if trainer:
                del trainer
            gc.collect()
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU Memory Cleared.")

    print("\n" + "="*60)
    print("ğŸ‰ All Experiments Finished!")
    print("="*60)

if __name__ == "__main__":
    run_grid_search()
