# ğŸ¯ æ¨ç†è¯„ä¼°å®Œæ•´ä¿®å¤ - å¿«é€ŸéªŒè¯æŒ‡å—

## âœ… ä¿®å¤å®Œæˆæ¸…å•

æ‰€æœ‰ä¸‰ä¸ªè¯„ä¼°æŒ‡æ ‡ç°åœ¨éƒ½ä¼šæ­£ç¡®ä¿å­˜åˆ°æ–‡ä»¶ï¼š

1. âœ… **LPIPS** (æ„ŸçŸ¥ç›¸ä¼¼åº¦) â†’ `lpips_results.json`
2. âœ… **CLIP** (å†…å®¹ä¸€è‡´æ€§) â†’ `clip_results.json`
3. âœ… **VGG** (é£æ ¼è·ç¦») â†’ `vgg_results.json`
4. âœ… **æ±‡æ€»æŠ¥å‘Š** â†’ `metrics_summary.json`

## ğŸš€ ç«‹å³éªŒè¯

### æ–¹æ³• 1: è¿è¡Œä¸€ä¸ªå¿«é€Ÿå®éªŒ

```bash
cd src
python auto_search.py
```

ç­‰å¾…ç¬¬ä¸€ä¸ªå®éªŒå®Œæˆåï¼Œæ£€æŸ¥è¾“å‡ºç›®å½•ï¼š

```
AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation/
â”œâ”€â”€ lpips_results.json
â”œâ”€â”€ clip_results.json
â”œâ”€â”€ vgg_results.json
â””â”€â”€ metrics_summary.json
```

### æ–¹æ³• 2: ä½¿ç”¨æµ‹è¯•è„šæœ¬éªŒè¯

å¦‚æœå·²ç»æœ‰è¯„ä¼°ç»“æœï¼š

```bash
cd src
python test_eval_save.py
```

ä¼šè‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„è¯„ä¼°ç›®å½•å¹¶éªŒè¯æ‰€æœ‰æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚

## ğŸ“Š æŸ¥çœ‹è¯„ä¼°ç»“æœ

### å‘½ä»¤è¡ŒæŸ¥çœ‹ï¼ˆå¿«é€Ÿï¼‰

```bash
# Windows
type AutoSearch_Results\Exp1_Baseline\checkpoints\evaluation\metrics_summary.json

# Linux/Mac
cat AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation/metrics_summary.json
```

### Python è„šæœ¬æŸ¥çœ‹ï¼ˆè¯¦ç»†ï¼‰

```python
import json
from pathlib import Path

# è¯»å–æ±‡æ€»æ–‡ä»¶
with open('AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation/metrics_summary.json', 'r') as f:
    data = json.load(f)

# æ‰“å°åŸºæœ¬ä¿¡æ¯
print(f"å®éªŒ: {data['experiment_name']}")
print(f"æ—¶é—´: {data['evaluation_time']}")

# æ‰“å°å„æŒ‡æ ‡çš„å…¨å±€å¹³å‡å€¼
for metric_name, metric_data in data['metrics'].items():
    print(f"\n{metric_name.upper()}:")
    if 'overall_average' in metric_data:
        for style, values in metric_data['overall_average'].items():
            print(f"  {style}: {values['mean']:.6f} Â± {values['std']:.6f}")
```

## ğŸ” éªŒè¯ä¿®å¤çš„å…³é”®ç‚¹

### 1. æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥

```bash
cd AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation
ls -la  # Linux/Mac
dir     # Windows
```

åº”è¯¥çœ‹åˆ° 4 ä¸ª JSON æ–‡ä»¶ã€‚

### 2. æ–‡ä»¶å†…å®¹æ£€æŸ¥

æ¯ä¸ªæ–‡ä»¶åº”è¯¥åŒ…å«ï¼š
- âœ… `metric` å­—æ®µ
- âœ… `per_subdirectory` è¯¦ç»†åˆ†ç»„ç»Ÿè®¡
- âœ… `overall_average` å…¨å±€ç»Ÿè®¡
- âœ… æ¯ä¸ªç»Ÿè®¡åŒ…å« `mean`, `std`, `count`

### 3. æ•°å€¼åˆç†æ€§æ£€æŸ¥

- **LPIPS**: é€šå¸¸åœ¨ 0.0-1.0 ä¹‹é—´ï¼Œè¶Šä½è¶Šå¥½
- **CLIP**: é€šå¸¸åœ¨ 0.6-1.0 ä¹‹é—´ï¼Œè¶Šé«˜è¶Šå¥½ï¼ˆ1.0 è¡¨ç¤ºå®Œå…¨ç›¸åŒï¼‰
- **VGG**: åŸå§‹å€¼å¾ˆå°ï¼ˆéœ€è¦ x1e5 ç¼©æ”¾ï¼‰ï¼Œè¶Šä½è¶Šå¥½

## âš ï¸ å¦‚æœå‡ºç°é—®é¢˜

### é—®é¢˜ 1: è¯„ä¼°æ–‡ä»¶ä¸å­˜åœ¨

**å¯èƒ½åŸå› **ï¼š
- è®­ç»ƒæœªå®Œæˆå°±ä¸­æ–­
- checkpoint æ–‡ä»¶æŸå
- é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ checkpoint æ˜¯å¦å­˜åœ¨
ls AutoSearch_Results/Exp1_Baseline/checkpoints/stage1_final.pt

# æ‰‹åŠ¨è¿è¡Œè¯„ä¼°
cd src
python -c "
from eval_lpips import Evaluator
eval_dir = '../AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation'
Evaluator('../AutoSearch_Results/Exp1_Baseline/checkpoints/stage1_final.pt').evaluate(
    '../wikiart_dataset/testA', 
    batch_size=2, 
    save_dir=eval_dir
)
"
```

### é—®é¢˜ 2: JSON æ–‡ä»¶ä¸ºç©ºæˆ–æŸå

**å¯èƒ½åŸå› **ï¼š
- æ¨ç†è¿‡ç¨‹ä¸­æ–­
- ç£ç›˜ç©ºé—´ä¸è¶³
- æƒé™é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# åˆ é™¤æŸåçš„è¯„ä¼°ç›®å½•
rm -rf AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation  # Linux/Mac
rmdir /s AutoSearch_Results\Exp1_Baseline\checkpoints\evaluation  # Windows

# é‡æ–°è¿è¡Œè¯„ä¼°ï¼ˆè§ä¸Šé¢çš„æ‰‹åŠ¨è¿è¡Œå‘½ä»¤ï¼‰
```

### é—®é¢˜ 3: æŸä¸ªæŒ‡æ ‡å§‹ç»ˆæŠ¥é”™

**å¯èƒ½åŸå› **ï¼š
- æ¨¡å‹æ–‡ä»¶æ ¼å¼ä¸å…¼å®¹
- ä¾èµ–åŒ…ç‰ˆæœ¬é—®é¢˜
- æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ä¾èµ–
pip list | grep -E "torch|lpips|clip|torchvision"

# é™ä½ batch sizeï¼ˆç¼–è¾‘ auto_search.pyï¼‰
# å°† batch_size=2 æ”¹ä¸º batch_size=1

# æ£€æŸ¥æ˜¾å­˜
nvidia-smi
```

## ğŸ“ ä¿®å¤è¯¦ç»†è¯´æ˜

å®Œæ•´çš„æŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒï¼š[EVALUATION_FIX_SUMMARY.md](EVALUATION_FIX_SUMMARY.md)

## ğŸ‰ ç¡®è®¤ä¿®å¤æˆåŠŸ

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼Œå¦‚æœçœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼Œè¯´æ˜ä¿®å¤æˆåŠŸï¼š

```
============================================================
ğŸ“‚ æ£€æŸ¥è¯„ä¼°ç›®å½•: AutoSearch_Results/Exp1_Baseline/checkpoints/evaluation
============================================================
âœ… lpips_results.json å­˜åœ¨
   â””â”€ Metric: LPIPS
   â””â”€ Overall averages: ['style_0', 'style_1']
âœ… clip_results.json å­˜åœ¨
   â””â”€ Metric: CLIP
   â””â”€ Overall averages: ['style_0', 'style_1']
âœ… vgg_results.json å­˜åœ¨
   â””â”€ Metric: VGG_Style
   â””â”€ Overall averages: ['style_0', 'style_1']
âœ… metrics_summary.json å­˜åœ¨
   â””â”€ Contains metrics: ['lpips', 'clip', 'vgg']
============================================================
âœ… æ‰€æœ‰è¯„ä¼°æ–‡ä»¶éƒ½æ­£ç¡®ä¿å­˜ï¼
```

---

**æœ€åä¿®æ”¹æ—¶é—´**: 2026-01-21  
**ä¿®å¤è€…**: GitHub Copilot  
**ä¿®å¤å†…å®¹**: å®Œæ•´å®ç°ä¸‰ä¸ªå®šé‡æŒ‡æ ‡çš„æ–‡ä»¶ä¿å­˜åŠŸèƒ½
