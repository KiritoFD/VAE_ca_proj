import torch
import torch.nn as nn
from torch.utils.data import DataLoader, WeightedRandomSampler
from tqdm import tqdm
from pathlib import Path
import json
import os
import random
import numpy as np
from PIL import Image
from diffusers import AutoencoderKL
import re
EVAL_INTERVAL = 1
# å¼•ç”¨ä½ çš„æ¨¡å‹å’Œæ•°æ®é›†
from SAFlow import SAFModel
from dataset import Stage1Dataset, Stage2Dataset

def load_config():
    with open("config.json", 'r', encoding='utf-8') as f:
        return json.load(f)

class ReflowTrainer:
    def __init__(self):
        self.cfg = load_config()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # è·¯å¾„è®¾ç½®
        self.ckpt_dir = Path(self.cfg['checkpoint']['save_dir'])
        self.ckpt_dir.mkdir(exist_ok=True)
        self.reflow_dir = Path(self.cfg['training']['reflow_data_dir'])
        self.vis_root = self.ckpt_dir / "visualizations"
        self.vis_root.mkdir(exist_ok=True)
        
        # åŠ è½½ VAE
        print("â³ Loading VAE for visualization...")
        self.vae = AutoencoderKL.from_pretrained(
            "runwayml/stable-diffusion-v1-5", 
            subfolder="vae"
        ).to(self.device)
        self.vae.eval()
        self.vae.requires_grad_(False)
        
        print(f"ğŸš€ Initialized Trainer on {self.device}")
        
    def get_model(self):
        return SAFModel(**self.cfg['model']).to(self.device)

    def resume_checkpoint(self, model, stage_prefix):
        """è‡ªåŠ¨æ–­ç‚¹ç»­ä¼ """
        ckpts = list(self.ckpt_dir.glob(f"{stage_prefix}_epoch*.pt"))
        if not ckpts:
            print(f"âšª No resume checkpoint for {stage_prefix}, starting from Epoch 1.")
            return 1

        def extract_epoch(p):
            match = re.search(r'epoch(\d+)', p.name)
            return int(match.group(1)) if match else 0
        
        latest_ckpt = max(ckpts, key=extract_epoch)
        latest_epoch = extract_epoch(latest_ckpt)
        print(f"ğŸŸ¢ Resuming {stage_prefix} from Epoch {latest_epoch} (File: {latest_ckpt.name})")
        model.load_state_dict(torch.load(latest_ckpt, map_location=self.device))
        return latest_epoch + 1

    def compute_loss(self, model, x_start, x_end, s_label, use_dropout=False):
        B = x_start.size(0)
        t = torch.rand(B, device=self.device)
        t_view = t.view(-1, 1, 1, 1)
        
        x_t = (1 - t_view) * x_start + t_view * x_end
        
        if use_dropout and random.random() < 0.1:
            x_cond = torch.zeros_like(x_start)
        else:
            x_cond = x_start

        v_pred = model(x_t, x_cond, t, s_label)
        v_target = x_end - x_start
        
        return nn.functional.mse_loss(v_pred, v_target)

    @torch.no_grad()
    def decode_latent_to_image(self, latents):
        latents = latents / 0.18215 
        imgs = self.vae.decode(latents).sample
        imgs = (imgs / 2 + 0.5).clamp(0, 1)
        imgs = imgs.cpu().permute(0, 2, 3, 1).numpy()
        return (imgs * 255).astype('uint8')

    @torch.no_grad()
    def do_inference(self, model, x_content, epoch, stage_name):
        model.eval()
        save_dir = self.vis_root / stage_name / f"epoch_{epoch}"
        save_dir.mkdir(parents=True, exist_ok=True)

        x_c = x_content[0:1].to(self.device) 
        num_styles = self.cfg['model']['num_styles']
        
        img_c = self.decode_latent_to_image(x_c)[0]
        Image.fromarray(img_c).save(save_dir / "content_source.jpg")
        
        for s_idx in range(num_styles):
            s_id = torch.tensor([s_idx], dtype=torch.long, device=self.device)
            x_t = x_c.clone()
            dt = 1.0 / 20 
            
            for step in range(20):
                t = torch.ones(1, device=self.device) * (step * dt)
                v = model(x_t, x_c, t, s_id)
                x_t = x_t + v * dt
            
            img_g = self.decode_latent_to_image(x_t)[0]
            Image.fromarray(img_g).save(save_dir / f"style_{s_idx}_result.jpg")

        print(f"ğŸ–¼ï¸ Inference done. Saved to {save_dir}")
        model.train()

    def make_balanced_sampler(self, dataset):
        print("âš–ï¸ è®¡ç®—ç±»åˆ«æƒé‡ï¼Œå¯ç”¨å¹³è¡¡é‡‡æ ·...")
        targets = []
        for f in dataset.all_files:
            class_name = f.parent.name
            class_id = dataset.class_to_id[class_name]
            targets.append(class_id)
        targets = np.array(targets)
        
        class_counts = np.bincount(targets)
        print(f"   ç±»åˆ«æ ·æœ¬åˆ†å¸ƒ: {class_counts} (ç´¢å¼•å¯¹åº”: {list(dataset.class_to_id.keys())})")
        
        class_weights = 1. / class_counts
        sample_weights = class_weights[targets]
        
        sampler = WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(sample_weights),
            replacement=True
        )
        return sampler

    def run_stage1(self):
        print("\nğŸš€ [Stage 1] Independent Coupling Training...")
        model = self.get_model()
        opt = torch.optim.AdamW(model.parameters(), lr=self.cfg['training']['learning_rate'])
        
        start_epoch = self.resume_checkpoint(model, "stage1")
        total_epochs = self.cfg['training']['stage1_epochs']
        
        if start_epoch > total_epochs:
            print("âœ… Stage 1 already completed.")
            return

        ds = Stage1Dataset(self.cfg['data']['data_root'], self.cfg['data']['num_classes'])
        sampler = self.make_balanced_sampler(ds)
        dl = DataLoader(ds, batch_size=self.cfg['training']['batch_size'], 
                        sampler=sampler, shuffle=False, 
                        num_workers=self.cfg['training']['num_workers'], drop_last=True)
        
        vis_batch = next(iter(dl))
        
        # ğŸ”´ å®šä¹‰æ¢é’ˆæ£€æŸ¥é¢‘ç‡ï¼šæ¯ä¸ªEpochæ£€æŸ¥4æ¬¡
        check_interval = max(1, len(dl) // 4)
        
        for epoch in range(start_epoch, total_epochs + 1):
            model.train()
            pbar = tqdm(dl, desc=f"S1 Epoch {epoch}/{total_epochs}")
            total_loss = 0
            smooth_loss = 0
            
            for step, (x_c, x_s, s_id) in enumerate(pbar):
                x_c, x_s, s_id = x_c.to(self.device), x_s.to(self.device), s_id.to(self.device)

                # ================= ğŸ” å¢å¼ºç‰ˆæ•°æ®æ¢é’ˆ (Periodic Probe) =================
                if step % check_interval == 0:
                    with torch.no_grad():
                        # 1. åŸºç¡€æ•°å€¼ç»Ÿè®¡
                        c_std = x_c.std().item()
                        s_std = x_s.std().item()
                        
                        # 2. çœŸå®å·®å¼‚è®¡ç®— (Target MSE)
                        diffs = (x_s - x_c).pow(2).view(x_c.size(0), -1).mean(dim=1)
                        avg_mse = diffs.mean().item()
                        
                        # 3. ç»Ÿè®¡â€œç–‘ä¼¼åŒå›¾â€çš„æ•°é‡ (MSE < 0.1)
                        suspicious_count = (diffs < 0.1).sum().item()
                        
                        tqdm.write(f"\nğŸ” [æ¢é’ˆ Step {step}] Avg Target MSE: {avg_mse:.4f} | Content Std: {c_std:.3f}")
                        
                        # 4. å®æ—¶æŠ¥è­¦é€»è¾‘
                        if c_std < 0.2:
                            tqdm.write(f"âŒ [æ•°å€¼æŠ¥è­¦] Stdè¿‡å° ({c_std:.4f})! ä»åœ¨è¿›è¡ŒäºŒæ¬¡ç¼©æ”¾ï¼")
                        elif suspicious_count > 0:
                            tqdm.write(f"âš ï¸ [é€»è¾‘æŠ¥è­¦] æœ¬Batchæœ‰ {suspicious_count}/{x_c.size(0)} å¼ å›¾å·®å¼‚è¿‡å°! (ç–‘ä¼¼åŒç±»é…å¯¹)")
                        elif avg_mse < 0.2:
                            tqdm.write(f"âš ï¸ [LossæŠ¥è­¦] ç†è®º Loss ä¸‹é™è¿‡ä½ ({avg_mse:.4f})! è¯·æ£€æŸ¥æ˜¯å¦åœ¨è®­ç»ƒæ’ç­‰æ˜ å°„ã€‚")
                        else:
                            # æ­£å¸¸æƒ…å†µä¸åˆ·å±ï¼Œåªæ˜¾ç¤ºç®€æŠ¥
                            pass
                # ====================================================================
                
                opt.zero_grad()
                loss = self.compute_loss(model, x_c, x_s, s_id, use_dropout=True)
                loss.backward()
                opt.step()
                
                loss_val = loss.item()
                total_loss += loss_val
                
                if step == 0: smooth_loss = loss_val
                else: smooth_loss = 0.9 * smooth_loss + 0.1 * loss_val
                pbar.set_postfix({"loss": f"{smooth_loss:.4f}"})
            
            print(f"ğŸ“Š Stage 1 Epoch {epoch} Avg Loss: {total_loss / len(dl):.6f}")
            
            if epoch % EVAL_INTERVAL == 0:
                self.do_inference(model, vis_batch[0], epoch, "stage1")
                torch.save(model.state_dict(), self.ckpt_dir / f"stage1_epoch{epoch}.pt")
                
        torch.save(model.state_dict(), self.ckpt_dir / "stage1_final.pt")

    # ... (run_generation, run_stage2, run_all ä¿æŒä¸å˜ï¼Œå¯ç›´æ¥ä½¿ç”¨ä¸Šä¸€ç‰ˆçš„å†…å®¹ï¼Œæˆ–éœ€è¦æˆ‘å†æ¬¡å®Œæ•´è´´å‡ºå—ï¼Ÿ) ...
    # ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œå‡è®¾ä½ ä¿ç•™äº†ä¹‹å‰ç‰ˆæœ¬çš„ run_generation å’Œ run_stage2
    # å¦‚æœä½ éœ€è¦æˆ‘å†è´´ä¸€éå®Œæ•´çš„è¿™éƒ¨åˆ†ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
    
    @torch.no_grad()
    def run_generation(self):
        # ... (åŒä¸Šä¸€ç‰ˆ) ...
        print("\nğŸŒŠ [Reflow] Data Synthesis...")
        self.reflow_dir.mkdir(exist_ok=True)
        model = self.get_model()
        
        s1_path = self.ckpt_dir / "stage1_final.pt"
        if not s1_path.exists(): raise FileNotFoundError("Stage 1 final model not found!")
            
        print(f"Loading {s1_path}...")
        model.load_state_dict(torch.load(s1_path, map_location=self.device))
        model.eval()
        
        ds = Stage1Dataset(self.cfg['data']['data_root'], self.cfg['data']['num_classes'])
        dl = DataLoader(ds, batch_size=self.cfg['training']['batch_size'], shuffle=False)
        
        cnt = 0
        for x_c, _, s_id in tqdm(dl, desc="Synthesizing"):
            x_c, s_id = x_c.to(self.device), s_id.to(self.device)
            x_t = x_c.clone()
            dt = 1.0 / 20
            for i in range(20):
                t = torch.ones(x_c.size(0), device=self.device) * (i * dt)
                v = model(x_t, x_c, t, s_id)
                x_t = x_t + v * dt
            
            for i in range(x_c.size(0)):
                torch.save({
                    'content': x_c[i].cpu(), 
                    'z': x_t[i].cpu(), 
                    'style_label': s_id[i].cpu()
                }, self.reflow_dir / f"pair_{cnt}.pt")
                cnt += 1
        print(f"âœ… Generated {cnt} pairs.")

    def run_stage2(self):
        # ... (åŒä¸Šä¸€ç‰ˆ) ...
        print("\nâœ¨ [Stage 2] Straightening Training...")
        model = self.get_model()
        opt = torch.optim.AdamW(model.parameters(), lr=self.cfg['training']['learning_rate'])
        
        start_epoch = self.resume_checkpoint(model, "stage2")
        total_epochs = self.cfg['training']['stage2_epochs']

        if start_epoch > total_epochs:
            print("âœ… Stage 2 already completed.")
            return
            
        ds = Stage2Dataset(self.reflow_dir)
        dl = DataLoader(ds, batch_size=self.cfg['training']['batch_size'], shuffle=True, 
                        num_workers=self.cfg['training']['num_workers'], drop_last=True)
        
        vis_batch = next(iter(dl))
        
        for epoch in range(start_epoch, total_epochs + 1):
            model.train()
            pbar = tqdm(dl, desc=f"S2 Epoch {epoch}/{total_epochs}")
            total_loss = 0
            smooth_loss = 0
            
            for step, (x_c, z, s_id) in enumerate(pbar):
                x_c, z, s_id = x_c.to(self.device), z.to(self.device), s_id.to(self.device)
                
                opt.zero_grad()
                loss = self.compute_loss(model, x_c, z, s_id, use_dropout=False)
                loss.backward()
                opt.step()
                
                loss_val = loss.item()
                total_loss += loss_val
                
                if step == 0: smooth_loss = loss_val
                else: smooth_loss = 0.9 * smooth_loss + 0.1 * loss_val
                pbar.set_postfix({"loss": f"{smooth_loss:.6f}"})
            
            print(f"ğŸ“Š Stage 2 Epoch {epoch} Avg Loss: {total_loss / len(dl):.8f}")
            
            if epoch % EVAL_INTERVAL == 0:
                self.do_inference(model, vis_batch[0], epoch, "stage2")
                torch.save(model.state_dict(), self.ckpt_dir / f"stage2_epoch{epoch}.pt")
                
        torch.save(model.state_dict(), self.ckpt_dir / "saf_final_reflowed.pt")

    def run_all(self):
        if not (self.ckpt_dir / "stage1_final.pt").exists():
            self.run_stage1()
        if not self.reflow_dir.exists() or len(list(self.reflow_dir.glob("*.pt"))) == 0:
            self.run_generation()
        self.run_stage2()

if __name__ == "__main__":
    trainer = ReflowTrainer()
    trainer.run_all()