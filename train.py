import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pathlib import Path
import os
from tqdm import tqdm
import glob
import re
import torch.cuda.amp as amp
from PIL import Image
import numpy as np
import random

from SAFlow import SAFModel
from dataset import RandomPairDataset
from config import Config


def find_best_checkpoint(checkpoint_dir):
    """Find the best checkpoint (SAF_best.pt)"""
    best_path = checkpoint_dir / "SAF_best.pt"
    if best_path.exists():
        return best_path
    return None


def find_latest_checkpoint(checkpoint_dir):
    """Find the latest checkpoint by epoch number"""
    checkpoints = list(checkpoint_dir.glob("SAF_epoch*.pt"))
    if not checkpoints:
        return None
    
    # Extract epoch numbers and find the maximum
    epoch_numbers = []
    for ckpt in checkpoints:
        match = re.search(r'epoch(\d+)', ckpt.name)
        if match:
            epoch_numbers.append((int(match.group(1)), ckpt))
    
    if epoch_numbers:
        latest = max(epoch_numbers, key=lambda x: x[0])
        return latest[1]
    return None


def load_checkpoint(checkpoint_path, model, optimizer=None, scheduler=None, scaler=None, device='cpu'):
    """
    Load checkpoint and return starting epoch and best loss
    """
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # Handle both full checkpoint and state_dict only
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        start_epoch = checkpoint.get('epoch', 0)
        best_loss = checkpoint.get('loss', float('inf'))
        
        if optimizer is not None and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if scheduler is not None and 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        if scaler is not None and 'scaler_state_dict' in checkpoint:
            scaler.load_state_dict(checkpoint['scaler_state_dict'])
        
        print(f"Resumed from epoch {start_epoch} with loss {best_loss:.4f}")
    else:
        # Just state dict
        model.load_state_dict(checkpoint)
        start_epoch = 0
        best_loss = float('inf')
        print("Loaded model state dict only (no training state)")
    
    return start_epoch, best_loss


def compute_loss(model, batch, device):
    """
    SA-Flow v2 æŸå¤±è®¡ç®—ï¼š
    Flow Path: Noise -> Style (é˜²æ­¢ä»£æ•°æ³„éœ²)
    Condition: Content (with Augmentation & CFG Dropout)
    """
    x_content, x_style, style_label = batch
    x_content = x_content.to(device, non_blocking=True)
    x_style = x_style.to(device, non_blocking=True)
    style_label = style_label.to(device, non_blocking=True)
    batch_size = x_content.shape[0]
    
    # ğŸ”´ ä¿®æ­£ç‚¹ 1: è·¯å¾„é‡å®šä¹‰ (é˜²æ­¢æ³„éœ²)
    # èµ·ç‚¹ x0 = çº¯å™ªå£° (ä¸æ˜¯å†…å®¹å›¾!)
    # ç»ˆç‚¹ x1 = é£æ ¼å›¾
    # è¿™æ ·æ¨¡å‹å¿…é¡»å­¦ä¼šç”Ÿæˆï¼Œè€Œä¸æ˜¯åšå‡æ³•
    x_0 = torch.randn_like(x_style)
    x_1 = x_style
    
    # ğŸ”´ ä¿®æ­£ç‚¹ 2: æ¡ä»¶å¢å¼º (Condition Augmentation)
    # ç»™æ¡ä»¶åŠ ä¸€ç‚¹å™ªå£°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆåˆ°åƒç´ çº§å¯¹é½
    x_cond = x_content + torch.randn_like(x_content) * 0.05
    
    # ğŸ”´ ä¿®æ­£ç‚¹ 3: CFG Training (Dropout)
    # 15% æ¦‚ç‡æŠŠæ¡ä»¶ç½®é›¶ï¼Œè®©æ¨¡å‹å­¦ä¼š"ç›²ç”»"
    # è¿™æ˜¯æ¨ç†æ—¶èƒ½åš CFG é”åŒ–çš„å‰æï¼
    cfg_dropout_mask = torch.rand(batch_size, device=device) < 0.15
    if cfg_dropout_mask.any():
        x_cond[cfg_dropout_mask] = 0.0
    
    # Flow Matching æ’å€¼
    t = torch.rand(batch_size, device=device)
    t_exp = t[:, None, None, None]
    
    # x_t æ··åˆè·¯å¾„: ä»å™ªå£°åˆ°é£æ ¼å›¾
    x_t = (1 - t_exp) * x_0 + t_exp * x_1
    
    # ç›®æ ‡é€Ÿåº¦: v = x_1 - x_0
    v_true = x_1 - x_0
    
    # é¢„æµ‹é€Ÿåº¦
    v_pred = model(x_t, x_cond, t, style_label)
    
    # MSE æŸå¤±
    loss = nn.functional.mse_loss(v_pred, v_true)
    
    # --- è¯Šæ–­æŒ‡æ ‡ ---
    with torch.no_grad():
        v_true_flat = v_true.reshape(batch_size, -1)
        v_pred_flat = v_pred.reshape(batch_size, -1)
        
        # æ–¹å‘å¯¹é½åº¦
        cos_sim = nn.functional.cosine_similarity(v_true_flat, v_pred_flat, dim=1).mean().item()
        
        # å¼ºåº¦æ¯”
        mag_true = torch.norm(v_true_flat, dim=1).mean().item()
        mag_pred = torch.norm(v_pred_flat, dim=1).mean().item()
        mag_ratio = mag_pred / (mag_true + 1e-6)
        
        # v_true æ ‡å‡†å·®
        v_true_std = v_true.std().item()

    debug_info = {
        "cos_sim": cos_sim,
        "mag_ratio": mag_ratio,
        "v_true_std": v_true_std,
        "cfg_dropout_rate": cfg_dropout_mask.float().mean().item()
    }
    
    return loss, debug_info


def train_one_epoch(model, dataloader, optimizer, device, epoch, scaler):
    """SA-Flow v2 è®­ç»ƒå¾ªç¯"""
    model.train()
    total_metrics = {"loss": 0.0, "cos_sim": 0.0, "mag_ratio": 0.0}
    
    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Epoch {epoch}")
    
    for step, batch in pbar:
        # ç¬¬ä¸€ä¸ªbatchçš„æ•°æ®æ£€æŸ¥
        if step == 0 and epoch == 1:
            x_content, x_style, _ = batch
            print(f"\nğŸ” DEBUG: Data Statistics Check:")
            print(f"   Content - Mean: {x_content.mean():.4f}, Std: {x_content.std():.4f}")
            print(f"   Style   - Mean: {x_style.mean():.4f}, Std: {x_style.std():.4f}")
        
        optimizer.zero_grad()
        
        with torch.cuda.amp.autocast():
            loss, debug = compute_loss(model, batch, device)
        
        scaler.scale(loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        scaler.step(optimizer)
        scaler.update()
        
        # ç´¯è®¡æŒ‡æ ‡
        total_metrics["loss"] += loss.item()
        total_metrics["cos_sim"] += debug["cos_sim"]
        total_metrics["mag_ratio"] += debug["mag_ratio"]
        
        # è¿›åº¦æ¡æ˜¾ç¤º
        pbar.set_postfix({
            "L": f"{loss.item():.4f}",
            "Cos": f"{debug['cos_sim']:.3f}",
            "Mag": f"{debug['mag_ratio']:.3f}"
        })
        
        # æ¯100æ­¥è¯¦ç»†ç»Ÿè®¡
        if step > 0 and step % 100 == 0:
            print(f"\n[Step {step}] V_True_Std: {debug['v_true_std']:.4f}")
    
    avg_metrics = {k: v / len(dataloader) for k, v in total_metrics.items()}
    return avg_metrics


def run_inference_samples(model, vae, eval_configs, epoch, config, device):
    """SA-Flow v2 æ¨ç†ï¼šæ”¯æŒ CFG"""
    from torchvision import transforms

    model.eval()
    root_dir = Path("training_samples")
    root_dir.mkdir(exist_ok=True)

    inf_cfg = config.inference
    steps = inf_cfg.get('steps', 25)
    cfg_scale = inf_cfg.get('cfg_scale', 4.0)  # ğŸ”´ æ–°å¢ CFG å‚æ•°

    for eval_idx, eval_cfg in enumerate(eval_configs):
        img_dir = eval_cfg["img_dir"]
        target_styles = eval_cfg["target_styles"]
        img_files = []
        for ext in ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.webp"]:
            img_files.extend(glob.glob(os.path.join(img_dir, ext)))
        img_files = sorted(img_files)
        if not img_files:
            print(f"âš ï¸ No images found in {img_dir}, skipping eval {eval_idx}")
            continue
        img_path = random.choice(img_files)
        img = Image.open(img_path).convert("RGB").resize((512, 512))
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.5], [0.5])
        ])
        img_tensor = transform(img).unsqueeze(0).to(device)
        
        with torch.no_grad():
            latent = vae.encode(img_tensor).latent_dist.sample()
            latent = latent * 0.18215  # SD scaling

        eval_subdir = root_dir / f"epoch_{epoch:03d}" / f"eval{eval_idx}"
        eval_subdir.mkdir(parents=True, exist_ok=True)
        img.save(eval_subdir / "input.jpg")

        for style_id in target_styles:
            style_subdir = eval_subdir / f"style_{style_id}"
            style_subdir.mkdir(parents=True, exist_ok=True)
            style_tensor = torch.tensor([style_id], dtype=torch.long, device=device)
            
            # ğŸ”´ v2: ä»çº¯å™ªå£°å¼€å§‹ (ä¸è®­ç»ƒä¸€è‡´)
            x_t = torch.randn_like(latent)
            cond_latent = latent
            uncond_latent = torch.zeros_like(latent)  # CFG æ— æ¡ä»¶è¾“å…¥
            
            dt = 1.0 / steps
            with torch.no_grad():
                for i in range(steps):
                    t_current = torch.tensor([i * dt], device=device)
                    
                    # ğŸ”´ CFG: æœ‰æ¡ä»¶ + æ— æ¡ä»¶é¢„æµ‹
                    v_cond = model(x_t, cond_latent, t_current, style_tensor)
                    v_uncond = model(x_t, uncond_latent, t_current, style_tensor)
                    
                    # CFG å¤–æ¨: æ”¾å¤§æ¡ä»¶å¸¦æ¥çš„ç‰¹å¾
                    v_final = v_uncond + cfg_scale * (v_cond - v_uncond)
                    
                    x_t = x_t + dt * v_final
                
                decoded = vae.decode(x_t / 0.18215).sample
                
            output = (decoded[0].permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5).clip(0, 1)
            output = (output * 255).astype(np.uint8)
            out_img = Image.fromarray(output)
            out_img.save(style_subdir / "output.jpg")
        print(f"âœ… Saved eval {eval_idx} (CFG={cfg_scale}) for epoch {epoch}")

    model.train()


def main():
    # ========== åŠ è½½é…ç½® ==========
    config = Config("config.json")
    config.print_config()
    
    # è§£åŒ…é…ç½®
    model_cfg = config.model
    train_cfg = config.training
    data_cfg = config.data
    ckpt_cfg = config.checkpoint
    
    # ä¿å­˜è·¯å¾„
    CHECKPOINT_DIR = Path(ckpt_cfg['save_dir'])
    CHECKPOINT_DIR.mkdir(exist_ok=True)
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    if train_cfg['use_amp']:
        print(f"Mixed Precision Training (AMP): Enabled")
    
    # ========== åˆå§‹åŒ– AMP Scaler ==========
    scaler = torch.cuda.amp.GradScaler() if train_cfg['use_amp'] else None
    
    # ========== æ•°æ®åŠ è½½ ==========
    print("Loading dataset...")
    dataset = RandomPairDataset(
        data_cfg['content_dir'], 
        data_cfg['style_root'], 
        num_classes=data_cfg.get('num_classes')
    )
    dataloader = DataLoader(
        dataset,
        batch_size=train_cfg['batch_size'],
        shuffle=True,
        num_workers=train_cfg.get('num_workers', 4),
        pin_memory=True
    )
    
    # ========== æ¨¡å‹åˆå§‹åŒ– ==========
    print("Initializing SA-Flow Model...")
    # æ³¨æ„ï¼šè¿™é‡Œçš„ SAFModel ç±»å…¶å®å·²ç»æ˜¯ SA-Flow æ¶æ„äº†
    model = SAFModel(**model_cfg).to(device)
    
    # ç»Ÿè®¡å‚æ•°é‡
    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Model parameters: {num_params / 1e6:.2f}M")
    
    # ========== åŠ è½½VAEï¼ˆç”¨äºæ¨ç†ï¼‰ ==========
    print("Loading VAE for inference...")
    from diffusers import AutoencoderKL
    vae = AutoencoderKL.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        subfolder="vae"
    ).to(device)
    vae.eval()
    
    # ========== ä¼˜åŒ–å™¨ ==========
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=train_cfg['learning_rate'],
        weight_decay=train_cfg['weight_decay']
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=train_cfg['num_epochs'],
        eta_min=1e-6
    )
    
    # ========== åŠ è½½æ£€æŸ¥ç‚¹ ==========
    start_epoch = 0
    best_loss = float('inf')
    
    resume_from = ckpt_cfg.get('resume_from')
    if resume_from:
        checkpoint_path = None
        
        if resume_from == "auto":
            checkpoint_path = find_best_checkpoint(CHECKPOINT_DIR)
            if checkpoint_path is None:
                checkpoint_path = find_latest_checkpoint(CHECKPOINT_DIR)
        elif resume_from == "best":
            checkpoint_path = find_best_checkpoint(CHECKPOINT_DIR)
        elif resume_from == "latest":
            checkpoint_path = find_latest_checkpoint(CHECKPOINT_DIR)
        
        if checkpoint_path and checkpoint_path.exists():
            start_epoch, best_loss = load_checkpoint(
                checkpoint_path, model, optimizer, scheduler, scaler, device
            )
        else:
            print("No checkpoint found, starting from scratch")
    
    if start_epoch > 0:
        for _ in range(start_epoch):
            scheduler.step()
    
    # ========== è®­ç»ƒå¾ªç¯ ==========
    print(f"Starting training from epoch {start_epoch + 1}...")
    
    eval_configs = config._config.get("eval_samples", [])
    inference_every_n_epochs = train_cfg.get('inference_every_n_epochs', 5)
    
    for epoch in range(start_epoch + 1, train_cfg['num_epochs'] + 1):
        avg_metrics = train_one_epoch(model, dataloader, optimizer, device, epoch, scaler)
        scheduler.step()
        
        # ğŸ”´ è¾“å‡ºå®Œæ•´è®­ç»ƒæŒ‡æ ‡
        print(f"\nEpoch {epoch}/{train_cfg['num_epochs']} Summary:")
        print(f"  Loss: {avg_metrics['loss']:.4f}")
        print(f"  Direction (CosSim): {avg_metrics['cos_sim']:.3f} {'âœ…' if avg_metrics['cos_sim'] > 0.7 else 'âš ï¸'}")
        print(f"  Strength (MagRatio): {avg_metrics['mag_ratio']:.3f} {'âœ… Clear' if avg_metrics['mag_ratio'] > 0.7 else 'âš ï¸ Blurry'}")
        print(f"  LR: {scheduler.get_last_lr()[0]:.6f}")

        # æ¯Nä¸ªepochè¿è¡Œæ¨ç†
        if epoch % inference_every_n_epochs == 0 and eval_configs:
            run_inference_samples(model, vae, eval_configs, epoch, config, device)

        # ä¿å­˜æ£€æŸ¥ç‚¹
        save_every = ckpt_cfg.get('save_every_n_epochs', 10)
        if epoch % save_every == 0 or avg_metrics['loss'] < best_loss:
            checkpoint_path = CHECKPOINT_DIR / f"SAF_epoch{epoch}_loss{avg_metrics['loss']:.4f}.pt"
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'scaler_state_dict': scaler.state_dict() if scaler else None,
                'loss': avg_metrics['loss'],
                'metrics': avg_metrics,  # ğŸ”´ ä¿å­˜è¯Šæ–­æŒ‡æ ‡
                'config': config._config,
            }, checkpoint_path)
            print(f"Saved checkpoint: {checkpoint_path}")
            
            if avg_metrics['loss'] < best_loss:
                best_loss = avg_metrics['loss']
                best_path = CHECKPOINT_DIR / "SAF_best.pt"
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'scaler_state_dict': scaler.state_dict() if scaler else None,
                    'loss': avg_metrics['loss'],
                    'metrics': avg_metrics,
                    'config': config._config,
                }, best_path)
                print(f"New best model saved: {best_path}")
    
    print("Training completed!")


if __name__ == "__main__":
    main()